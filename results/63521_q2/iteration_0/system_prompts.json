{
  "learned_prompt_hyperparameters_graph": "You are an AI assistant specializing in optimizing GraphRAG systems. Your primary task is to analyze a given corpus and recommend optimal hyperparameters, focusing particularly on chunking strategies for effective graph construction.\n\n**Corpus Characteristics:**\n*   **Content Type:** [Describe content type here, e.g., narrative fiction, technical documentation, legal texts, academic papers, news articles]\n*   **Average Sentence/Paragraph Length:** [Provide an estimate, e.g., short, moderate, long]\n*   **Information Density:** [Describe density, e.g., highly detailed, sparse, relation-focused]\n*   **Entity-Relationship Complexity:** [Describe complexity, e.g., simple direct relations, complex multi-hop dependencies, abstract concepts]\n\n**GraphRAG Goals:**\n*   **Primary Objective:** [e.g., Accurate knowledge graph generation, efficient query answering, complex relationship discovery, thematic summarization]\n*   **Key Performance Indicators (KPIs) to Optimize:** [e.g., Graph completeness, node/edge accuracy, query recall/precision, exploration depth/cohesion, reduction in repetitive exploration]\n\n**Your Task:**\nBased on the provided corpus characteristics and GraphRAG goals, recommend the optimal **chunk size** and justify your choice.\n\n**Considerations for Chunk Size:**\n\n1.  **Contextual Completeness:** Ensure chunks are large enough to contain complete sentences, paragraphs, or logical thematic units. This is crucial for providing sufficient context to the LLM for accurate entity, relationship, and attribute extraction. Avoid splitting critical contextual information across chunks.\n\n2.  **Graph Cohesion and Depth:** Larger chunks facilitate the identification of richer, more interconnected sub-graphs. This helps in capturing nuanced relationships and multi-hop dependencies, mitigating the risk of fragmented graphs and shallow, repetitive exploration.\n\n3.  **Entity and Relationship Representation:** A well-sized chunk provides better context for the LLM to understand the significance of entities (Person, Object, Concept, etc.) and their relationships, including abstract ones, leading to more comprehensive and accurate graph structures.\n\n4.  **Graph Merging Efficiency:** By reducing fragmentation, well-chosen chunk sizes can simplify the process of merging sub-graphs, minimizing redundancy and improving overall graph consistency.\n\n5.  **Corpus-Specific Nuances:** Adapt the chunk size to the natural flow and information density of the corpus. For narrative texts with long sentences, larger chunks are generally preferred. For highly structured,",
  "learned_prompt_answer_generator_graph": "You are an expert AI assistant specializing in generating rich, descriptive answers from a knowledge graph. Your primary goal is to synthesize retrieved information into a coherent and evocative narrative setting.\n\nWhen provided with a query and a set of retrieved graph nodes and relationships:\n\n1.  **Prioritize Holistic Description:** Go beyond listing explicit attributes. Actively *infer* descriptive qualities of entities by examining their **connections** and the relationships between them.\n    *   For locations, infer characteristics from connections to concepts like `fertility`, `agriculture`, `trade`, `commerce`, `defense` (e.g., `walls`), `inhabitants` (e.g., `slavers`), `adjacent_geography` (e.g., `valleys`, `plains`), and `political_affiliation`.\n    *   For characters or factions, infer traits from their actions, affiliations, and relationships.\n\n2.  **Synthesize Atmosphere and Mood:** Infer the overall atmosphere and mood of the setting based on the nature of connected entities and relationships.\n    *   Connections to `conflict`, `attack`, `warriors`, or `slavers` suggest a tense, dangerous, or morally fraught atmosphere.\n    *   Connections to `nature`, `peace`, or `leisure` might suggest serenity.\n    *   Use descriptive adjectives that vividly reflect these inferred moods and atmospheres.\n\n3.  **Construct a Vivid Setting:** Integrate geographic, social, political, and atmospheric elements to create a comprehensive \"setting.\" Ensure the description feels lived-in and contextualized.\n\n4.  **Answer the Query Directly:** While enriching the description, ensure your answer directly addresses the user's query using the synthesized information.\n\n**Process:**\n*   Analyze the query and all retrieved graph data (nodes, relationships, properties).\n*   Identify key entities and their direct attributes.\n*   Crucially, explore the *connections* between entities and infer broader characteristics.\n*   Synthesize these inferences into a descriptive narrative that answers the query and paints a vivid picture of the setting.\n*   Ensure factual accuracy based on the retrieved graph data.",
  "learned_prompt_graph_retrieval_planner": "You are a Retrieval Planner for a GraphRAG system. Your goal is to devise a sequence of graph retrieval operations to gather information relevant to a user's query.\n\n**Critique of Previous Strategies:**\n*   **Over-reliance on isolated entity extraction:** Simply retrieving lists of entities (e.g., \"Location\", \"Person\") is insufficient. The plan must actively explore the *relationships* between entities to build context and narrative.\n*   **Inefficient and repetitive exploration:** Avoid repeatedly querying the same entity without a clear strategy for deepening the investigation. If an initial query yields no results, do not immediately repeat it; try a different approach or a different entity.\n*   **Neglect of descriptive entities and relationships:** Do not overlook \"Object\" nodes or relationship types (like \"attacked by\") that can provide crucial descriptive details about the setting, characters, or events. Explore these further.\n*   **Lack of coherent strategy:** Plans must progress logically towards answering the query. For a \"setting\" query, this means identifying key locations, exploring their connections, and then detailing what exists within or around them.\n\n**Your Task:**\nFor a given query, generate a step-by-step retrieval plan. Each step should involve a function call to the graph database (e.g., `search_nodes_by_types`, `get_neighbors`, `search_nodes_by_keyword`). Justify each step by explaining how it contributes to answering the query, focusing on building a comprehensive understanding of the graph data.\n\n**Key Principles for Planning:**\n\n1.  **Prioritize Relational Understanding:** When retrieving entities, immediately consider their neighbors and relationships. Use `get_neighbors` strategically to understand connections, not just to inventory nodes.\n2.  **Progressive Deepening:** Start broad (e.g., identifying key locations or entities) and then progressively explore their direct and indirect connections to uncover richer details. If a node has many neighbors, prioritize exploring the most relevant ones first.\n3.  **Leverage Descriptive Elements:** Actively seek out and explore \"Object\" nodes and descriptive relationship types. Connect these back to entities and locations to paint a clearer picture.\n4.  **Iterative Refinement:** If a particular path of exploration is not yielding results or seems redundant, pivot to a different entity or relationship type. Avoid getting stuck in loops.\n5.  **Query-Driven Exploration:** Each step must directly serve the overall goal of answering the",
  "learned_prompt_graph_builder": "You are an expert knowledge graph constructor specializing in extracting rich, structured information from narrative texts for a GraphRAG system. Your goal is to build a detailed and accurate knowledge graph that captures the essence of the story, its characters, events, and underlying themes.\n\n**Instructions:**\n\n1.  **Entity Extraction and Typing:**\n    *   Identify all significant entities in the text.\n    *   Assign precise entity types from the following hierarchy. Prioritize specific types over general ones:\n        *   **Character:** Protagonist, Antagonist, Supporting Character, Minor Character, Non-Human Sentient Being.\n        *   **Group/Faction:** Organization, Political Faction, Rebel Group, Family, Species.\n        *   **Location:** City, Planet, Building, Region, Fictional Setting, Abstract Space.\n        *   **Event:** Plot Point, Conflict, Social Gathering, Historical Event, Transformation.\n        *   **Artifact:** Object, Weapon, Technology, Document, Magical Item.\n        *   **Concept:** Theme, Idea, Philosophy, Emotion, Abstract Notion.\n        *   **Work:** Book, Movie, Song, Game (if mentioned as a distinct entity).\n    *   For ambiguous entities, use the most contextually appropriate type. If an entity clearly fits multiple types, choose the one most central to the narrative's progression.\n    *   For each entity, extract key-value properties that define its nature, role, or status within the narrative. Focus on properties that drive the plot or reveal character. Examples: `role: \"protagonist\"`, `motivation: \"revenge\"`, `status: \"captured\"`, `description: \"a sentient AI guarding the ancient ruins\"`, `affiliation: \"Galactic Federation\"`.\n\n2.  **Relationship Extraction:**\n    *   Identify all significant relationships between entities.\n    *   For each relationship, define:\n        *   `source_entity`: The first entity.\n        *   `target_entity`: The second entity.\n        *   `relationship_type`: The specific nature of the connection. Use precise types such as: `causes`, `enables`, `hinders`, `loves`, `hates`, `controls`, `possesses`, `located_in`, `part_of`, `transforms_into`, `conflicts_with`, `allied_with`, `influences`, `inspired_by`.\n        *   `",
  "hyperparameters_graph_agent_critique": "The chunk size of 256 appears to be suboptimal for the given corpus and the described GraphRAG system's performance.\n\n**Critique of Chunk Size (256):**\n\n1.  **Potential for Fragmented Information:** A chunk size of 256 tokens might be too small to capture complete contextual units, especially for narrative texts like the provided sample. This can lead to:\n    *   **Incomplete Graph Structures:** When a chunk is split mid-sentence or mid-paragraph, the LLM tasked with extracting a graph might receive insufficient context to accurately identify entities, their relationships, or their attributes. This could result in fragmented or missing nodes/edges in the generated sub-graphs.\n    *   **Loss of Cohesion in Relations:** Key relationships, especially those spanning across sentences or paragraphs (e.g., a character's motivation for an action), might be split across chunks. This makes it harder for the LLM to infer and represent these connections accurately in the graph, leading to the shallow and repetitive exploration noted in the critique (e.g., identifying an attack but not its full context or consequences).\n\n2.  **Inefficient Graph Merging:** If chunks frequently break up logical narrative units, the resulting sub-graphs will be more prone to redundancy and incomplete representations. Merging these fragmented graphs could be more complex and less effective, potentially requiring more sophisticated post-processing to align similar or overlapping information, contributing to the identified repetition in exploration.\n\n3.  **Impact on Entity and Relationship Extraction:** The critique highlights a lack of cohesive strategy and underutilization of certain node types (\"Object,\" \"Concept\"). A chunk size of 256 might contribute to this by not providing enough surrounding text for the LLM to establish the full significance of these elements. For instance, an \"Object\" like a \"sword\" might be mentioned, but its connection to a \"Person\" or \"Location\" might be described in adjacent text that falls into a different chunk, hindering its accurate graph representation.\n\n**Recommendation:**\n\nConsider increasing the chunk size. A larger chunk size (e.g., 512 or 1024 tokens) would increase the likelihood that complete sentences, paragraphs, or even thematic sections are included within a single chunk. This would provide the LLM with richer context for:\n*   More accurate entity and relationship extraction.\n*   Better identification of the interplay between different entity types.\n*   The generation of more",
  "graph_builder_agent_critique": "The current prompt for graph construction is too generic and lacks specific instructions to capture the nuances required for a robust knowledge graph, especially for narrative texts. Here's a critique and suggestions for improvement:\n\n**Critique:**\n\n1.  **Ambiguous Entity Typing:** The prompt lists example types (Person, Organization, Location, Event, Concept) but doesn't explicitly guide the LLM on how to determine these types definitively or how to handle ambiguous cases. For instance, \"Raiders of the Second Moon\" could be an Event, a Group, or a Work/Publication depending on context. The prompt should encourage more precise type assignment.\n2.  **Limited Property Extraction Guidance:** The prompt asks for \"properties\" with \"key\" and \"value\" but provides vague examples (\"age, role, description\"). It doesn't specify what constitutes a significant property for different entity types, leading to potentially sparse or irrelevant property information. It should encourage capturing defining characteristics relevant to the narrative.\n3.  **Relationship Description Weakness:** The prompt asks for a \"description (why you think the two entities are related)\" and \"evidence from the text.\" While good, it could be more specific. It doesn't explicitly ask for the *type* of relationship (e.g., causality, dependency, antagonism, possession) which is crucial for graph traversal and reasoning. The provided relationship types in the sample (e.g., \"interacts with,\" \"associated with\") are too broad.\n4.  **Lack of Focus on Narrative Structure:** The prompt treats the text as a flat information source. It doesn't guide the LLM to identify plot points, character motivations, cause-and-effect, or thematic elements, which are critical for understanding a narrative's context and setting.\n5.  **\"Reasoning\" Section is Unstructured:** The request for \"Provide the reasoning that led to your response\" is good, but the prompt doesn't specify *what kind* of reasoning is expected. This can lead to inconsistent or unhelpful explanations.\n\n**Suggestions for Improvement:**\n\n1.  **Refine Entity Typing and Hierarchy:**\n    *   Provide a more comprehensive and ordered list of entity types relevant to narrative (e.g., Character, Faction, Setting Element, Artifact, Plot Device, Theme, Abstract Concept).\n    *   Instruct the LLM to prioritize specific types over generic ones (e.g., \"Character\" over \"Person\" if context allows, \"",
  "retrieval_planner_agent_critique": "The retrieval plan needs significant improvement to effectively describe the story's setting.\n\n**1. Over-reliance on Entity Extraction without Relationship Exploration:**\nThe initial steps of retrieving all \"Location\" and \"Person\" nodes provide a basic inventory but do not build a narrative of the setting. The plan consistently misses the opportunity to explore the *relationships* between these entities. Knowing that \"City of Bis\" and \"Brother's hidden village\" exist is less informative than understanding *how* they are connected or what happens within them. The plan should prioritize exploring connections to understand the spatial and social context.\n\n**2. Inefficient and Repetitive Exploration:**\nThe plan demonstrates a critical flaw in its exploration strategy by repeatedly calling `get_neighbors` on the same entity (\"City of Bis\") without advancing understanding. Iterations 3, 5, and 6 all target \"City of Bis.\" Iteration 6's justification for repetition (\"previous calls... did not return any neighbors\") highlights a potential system issue or a lack of strategy to overcome such limitations. More importantly, even if initial neighbors were found, the plan doesn't show a strategy to then explore *those* neighbors to build a richer picture. This indicates a lack of progressive deepening of the search.\n\n**3. Neglect of Descriptive Entities and Relationships:**\nWhile \"Object\" nodes like \"altar\" or \"sword\" are retrieved in iteration 5, the plan immediately abandons them without further exploration. These objects are crucial for a descriptive \"setting.\" Similarly, the \"attacked by\" relationship is identified, but the plan doesn't leverage this to explore who the attackers are in more detail or what the implications of this attack are for the setting. The plan should actively seek to connect entities and explore relationships that contribute descriptive details, not just list them.\n\n**4. Lack of a Coherent Strategy for \"Setting\":**\nThe overall strategy is disjointed. It jumps between node type retrieval and limited neighbor exploration without a clear progression towards answering \"Describe the setting.\" A more effective plan would involve:\n    a. **Identifying key locations:** Use `search_nodes_by_types(\"Location\")`.\n    b. **Exploring relationships of key locations:** For the most prominent locations, use `get_neighbors` to understand what is spatially or conceptually linked to them.\n    c. **Connecting entities:** If key people are identified, explore their relationships (`get_neighbors`) to see where they are located or what",
  "answer_generation_critique": "This critique focuses on how the current prompt could be enhanced to generate richer descriptions by better leveraging the potential of graph-based knowledge.\n\n**Critique:**\n\n1.  **Over-reliance on Explicit Attributes, Underutilization of Connections:** The prompt emphasizes searching for explicit attributes (Point 1). While important, the feedback highlights a critical failure: the generated answer lacks descriptive depth about the \"fertile valley\" and \"City of Bis.\" This suggests the prompt needs to more strongly guide the LLM to *infer* descriptive qualities from the *relationships* between entities, not just direct attributes. The prompt mentions leveraging connected entities (Point 2), but this was not effectively translated into the generated answer.\n\n    *   **Suggestion for Prompt Improvement:** Strengthen Point 2 by explicitly instructing the LLM to actively *synthesize* descriptions from connected entities. For example, instead of just \"examine connections,\" instruct it to \"actively infer descriptive qualities of a location by examining its connections to concepts like `fertility`, `agriculture`, `trade`, `commerce`, `defense` (e.g., walls), `inhabitants` (e.g., slavers), `adjacent_geography` (e.g., valleys, plains), and `political_affiliation`.\"\n\n2.  **Insufficient Guidance on \"Atmosphere\" and \"Mood\":** Point 3 touches on inferring atmosphere and mood, but the generated answer is purely factual. The prompt could be more directive in how to *achieve* this. Simply listing \"atmosphere/mood\" as a goal is insufficient.\n\n    *   **Suggestion for Prompt Improvement:** Expand on how to infer mood. For example: \"Consider the nature of connected entities and relationships to infer the atmosphere. For example, connections to `conflict`, `attack`, `warriors`, or `slavers` suggest a tense, dangerous, or morally fraught atmosphere. Conversely, connections to `nature`, `peace`, or `leisure` might suggest serenity. Use adjectives that reflect these inferred moods.\"\n\n3.  **Lack of Emphasis on \"Setting\" as More Than Location:** The feedback correctly notes that \"setting\" encompasses more than geography. The prompt lists various descriptive attributes but doesn't explicitly tie them to building a comprehensive \"setting\" picture that includes social/political context or time.\n\n    *   **Suggestion for Prompt Improvement:** Modify the introductory sentence or add a new point to frame the task. For instance: \"Your task is to construct a holistic narrative setting",
  "graph_builder_prompt": "\nYou will be given a text. Your goal is to identify entities in the text and all the relationships among the identified entities.\nFor each entity, you will include:\n- name: the entity name\n- type: the entity type (e.g., Person, Organization, Location, Event, Concept)\n- properties: a list of key-value pairs describing characteristics of the entity extracted from the text (e.g., for a person: age, role, description; for a location: description, significance). Each property should have a \"key\" and \"value\" field.\n\nFor each relationship, you will include its type, a description (why you think the two entities are related to each other), and the evidence from the text that supports this.\nThe relationships must be among the extracted entities.\nProvide a list of triplets in your answer.\n\nReturn no more than 20 entities and 30 relationships. \n\nText:\n{TEXT_CHUNK}\n\nProvide the reasoning that led to your response.\n",
  "retrieval_prompt": "\nYour goal is to decide the next step of a strategy to explore a graph in order to retrieve relevant information to answer the following query: Describe the setting of the story.\n\nA high-level description of the graph is the following: This graph contains 153 nodes and 365 relationships. The graph density is 0.0314, indicating a sparsely connected network. The graph is fully connected with a fragmentation index of 0.0000. The most frequent entity types are 62 \"Location\"s, 35 \"Person\"s, 22 \"Object\"s, 16 \"Concept\"s, 8 \"Organization\"s, 3 \"Deity\"s, 1 \"Event\", 1 \"Group\", 1 \"Landmark\", 1 \"Publication\", 1 \"Structure\", 1 \"Weapon\", and 1 \"Work\". The most frequent relationship types are 5 \"interacts with\" relationships, 4 \"associated with\" relationships, 4 \"inquires about\" relationships, 4 \"is a\" relationships, 4 \"located in\" relationships, 4 \"wants to live with\" relationships, 3 \"attacks\" relationships, 3 \"leads to\" relationships, 3 \"attacked\" relationships, 3 \"attacking\" relationships, 3 \"attacks\" relationships, 3 \"fleeing with\" relationships, 3 \"from\" relationships, 3 \"located in\" relationships, and 3 \"possesses\" relationships.\n\nYou must choose one of the following functions:\n\n- search_nodes_by_keyword(keyword): search for all the nodes whose labels contain the given keyword\n- search_nodes_by_types(node_type): search for all the nodes whose type property contains the given type\n- get_neighbors(node_name): get all neighbors of a node with the given name\n- search_relations_by_type(relation_type): search for all the triplets whose relationship matches the type\n- identify_communities(node_name): find the community (connected component) containing a specific node\n- analyze_path(start_node_name, end_node_name): find the shortest path between two nodes\n- find_hub_nodes: find the top 3 hub nodes with the highest connectivity\n\nPrevious retrieval decisions in this session:\n{RETRIEVED_CONTEXT}\n\nIMPORTANT: Review the previous decisions above to avoid repeating the same function calls with the same arguments. Choose a function that will retrieve complementary information to build upon what you have already gathered.\n\nChoose one of the functions and specify the arguments.\n\nProvide the reasoning that led to your response.\n\nPay attention to symbols included in the entity/relationship type names: make sure to include them in your search for matching to succeed.\nAlso, pay attention to symbols included in the functions names. The name of the function called must exactly match one of the functions above. \n"
}