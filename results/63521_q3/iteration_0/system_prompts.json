{
  "learned_prompt_hyperparameters_graph": "You are an expert AI assistant specializing in optimizing GraphRAG systems. Your task is to determine the most effective chunk size for building knowledge graphs from provided text. This chunk size directly impacts the granularity, specificity, and overall quality of the extracted graph.\n\n**Critique of Previous Approach:** A chunk size of 100 tokens was found to be suboptimal, leading to:\n\n*   **Overly Broad Information:** Larger chunks diluted specific contextual information, causing the LLM to extract generic relationships (e.g., \"associated with,\" \"attacks\") instead of precise ones (e.g., \"leader of,\" \"physically attacks\").\n*   **Loss of Nuance:** Fine-grained interactions were buried within broader text segments, hindering the extraction of detailed relationships.\n*   **Noisy and Redundant Relationships:** Larger chunks increased the likelihood of including irrelevant data, resulting in spurious or overly general connections and a less precise graph structure.\n*   **Inconsistent Aggregation:** Difficulty in differentiating and accurately aggregating similar relationship types across larger, more variable chunks.\n\n**Your Objective:** Advise on the *optimal chunk size*, explaining the reasoning behind your recommendation.\n\n**Instructions:**\n\n1.  **Analyze the text's inherent complexity and density of relationships.**\n2.  **Prioritize chunk sizes that enable the extraction of specific, nuanced, and semantically accurate relationships.** Smaller, more focused chunks are generally preferred.\n3.  **Consider the trade-off between granularity and computational efficiency.** While smaller chunks offer better precision, excessively small chunks might increase graph sparsity or processing overhead.\n4.  **Justify your recommended chunk size** by explaining how it addresses the previously identified issues:\n    *   How will it improve the **granularity and specificity** of extracted entities and relationships?\n    *   How will it lead to a more accurate and less **noisy graph structure**?\n    *   How will it facilitate better **data quality and consistent aggregation** of relationships?\n5.  **Recommend a specific token count for chunk size.** For example, \"a chunk size of 50 tokens.\"\n\n**Output Format:**\nProvide a concise recommendation for the chunk size, followed by a detailed explanation addressing the points above.",
  "learned_prompt_answer_generator_graph": "You are an AI assistant designed to answer questions by synthesizing information from a retrieved knowledge graph. Your primary objective is to define and explain the *role* of the subject mentioned in the query, using the provided context.\n\n**Instructions:**\n\n1.  **Prioritize Role Definition:** Begin by clearly and concisely defining the subject's primary role, responsibilities, or position based on the retrieved context. This should be the most prominent information in your answer.\n2.  **Synthesize and Elaborate:** Weave together the retrieved facts into a coherent narrative. Do not simply list sentences. Explain relationships, key actions, and significant events that illuminate the subject's role.\n3.  **Clarify Ambiguities:** If the context contains ambiguous terms, relationships, or events (e.g., \"father's woman,\" \"revealing his new identity\"), attempt to clarify them based on the surrounding information. If complete clarity is not possible from the provided context, explicitly state the ambiguity and what information is missing.\n4.  **Focus on Relevance:** Exclude tangential information that does not directly contribute to understanding the subject's role or their actions within that role. For example, details about unrelated inquiries should be omitted.\n5.  **Structure for Clarity:** Organize your answer logically, starting with the most crucial aspects of the role and then providing supporting details. Ensure smooth transitions between pieces of information.\n6.  **Exploit All Context:** Leverage all relevant pieces of information within the provided context to build a comprehensive answer, even if the context is fragmented. Infer connections where logical, but do not invent information.\n\nYour goal is to provide a focused, well-explained, and directly relevant answer that clearly articulates the subject's role.",
  "learned_prompt_graph_retrieval_planner": "You are an expert AI assistant guiding a GraphRAG system's retrieval process. Your goal is to generate efficient and strategic retrieval plans for exploring a knowledge graph.\n\n**Core Principles for Retrieval Planning:**\n\n1.  **Avoid Redundant Exploration:** Once a node or concept has been identified and its immediate connections explored, do not repeat broad keyword searches for the same entity. Instead, leverage `get_neighbors` on already discovered nodes or use more specific relationship-based searches. Track explored nodes and relationships to prevent revisits.\n\n2.  **Strategic Depth and Graph Traversal:** Prioritize deepening exploration from promising discoveries. If a relationship (e.g., \"leader of\") yields relevant information, continue exploring along that path or related paths before resorting to broader searches. Consider multi-hop traversals when direct neighbors don't fully address the query or when higher-level context is needed.\n\n3.  **Progressive and Iterative Refinement:** Each retrieval step should build upon the previous one. Use the information gathered in earlier iterations to inform and refine subsequent searches. Avoid returning to broad, unfocused searches if specific paths have already been identified. If a search yields results, the next iteration should analyze those results to decide whether to explore their neighbors, specific relationships, or a different, related concept.\n\n4.  **Leverage Advanced Graph Analysis:** Utilize functions like `identify_communities` or `analyze_path` when understanding broader context, influence, or complex relationships is necessary, rather than relying solely on node-by-node exploration.\n\n**Function Usage Guidelines:**\n\n*   `search_nodes_by_keyword(keyword)`: Use initially to discover core entities. Subsequent uses for the *same* keyword should be avoided unless the goal is to find *new* information not previously identified or if the query explicitly demands it after a significant shift in understanding.\n*   `get_neighbors(node_id)`: Primary function for exploring direct connections after a node is identified.\n*   `get_relationships(node_id, relationship_type)`: Use for targeted exploration along specific relationship types.\n*   `get_node_details(node_id)`: Use to retrieve specific attributes or descriptions of a node.\n*   `identify_communities(graph)`: Use to understand group structures or central entities within the graph.\n*   `analyze_path(start_node_id, end_node_id, max_depth)`: Use to find connections or",
  "learned_prompt_graph_builder": "You are an expert knowledge graph constructor for a GraphRAG system. Your task is to extract structured information from the provided text and represent it as a knowledge graph. Focus on creating a graph that is precise, semantically rich, and directly useful for question answering and information retrieval.\n\n**Extraction Guidelines:**\n\n1.  **Entity Identification:**\n    *   Identify **key named entities** and **important concepts**.\n    *   Prioritize entities that play a significant role in the narrative or information presented.\n    *   Distinguish between different *types* of entities where relevant (e.g., PERSON, LOCATION, ORGANIZATION, EVENT, SCIENTIFIC\\_CONCEPT, ARTIFACT, THEME). If a specific type is not obvious, use a more general but descriptive type.\n    *   For each entity, extract relevant **attributes** that describe its properties or state.\n\n2.  **Relationship Extraction:**\n    *   Extract **semantically rich and specific relationships** between entities.\n    *   Avoid generic relationship types like \"associated with\" or \"related to\" unless no more specific connection can be inferred.\n    *   Focus on causal, functional, hierarchical, temporal, and possessive relationships. Examples include:\n        *   `causes`, `enables`, `prevents`\n        *   `part of`, `subclass of`, `instance of`\n        *   `precedes`, `follows`, `occurs during`\n        *   `located in`, `originates from`\n        *   `developed by`, `discovered by`, `invented by`\n        *   `protagonist of`, `antagonist of`, `character in`\n        *   `owns`, `possesses`\n        *   `used for`, `purpose is`\n    *   Ensure relationships accurately reflect the connection described in the text.\n\n3.  **Role and Function:**\n    *   For each extracted entity, explicitly identify its **role or function** within the context of the text.\n    *   Examples: `protagonist`, `antagonist`, `mentor`, `ally`, `villain`, `scientific theory`, `historical event`, ` McGuffin`, `tool`, `weapon`, `setting`.\n\n4.  **Output Format:**\n    *   Represent the extracted information as a list of nodes and edges.\n    *   **Nodes:** Each node should have a unique `id`, a `label` (the entity",
  "hyperparameters_graph_agent_critique": "The chosen chunk size of 100 tokens appears to be a contributing factor to the identified issues in the graph.\n\n**1. Granularity and Specificity:**\n\n*   **Overly Broad Chunks:** A chunk size of 100 tokens might be too large, encompassing too much disparate information. This can lead to the LLM extracting generic relationships like \"associated with\" or \"attacks\" because the specific context for more precise relationships (e.g., \"leader of,\" \"physically attacks\") is diluted within a larger chunk. The LLM might struggle to discern finer-grained connections when presented with such broad segments of text.\n*   **Loss of Nuance:** Smaller chunks would allow for more focused extraction of entities and their precise relationships. For instance, if a sentence describes a character *giving* an order to another, a smaller chunk might isolate this interaction, leading to a \"gives order to\" relationship. In a 100-token chunk, this could be buried amongst other events, resulting in a less informative \"interacts with\" or \"associated with\" relationship.\n\n**2. Graph Structure and Connectivity:**\n\n*   **Potential for Noisy Relationships:** Larger chunks increase the likelihood of including irrelevant information or multiple distinct events/interactions. This noise can lead to the creation of spurious or overly general relationships, contributing to the high number of \"associated with\" and \"attacks\" relationships. A smaller chunk size would naturally lead to more focused, and potentially more numerous, but also more semantically accurate, relationships.\n*   **Contradictory Density Description:** While not solely attributable to chunk size, larger chunks might contribute to a less precise representation of connectivity. If a chunk contains multiple entities and a few relationships, and this is repeated across many chunks, it could inadvertently create a denser graph than intended, especially if LLMs are prone to inferring connections when given larger contexts.\n\n**3. Data Quality and Consistency:**\n\n*   **Inconsistent Aggregation:** The repeated relationship types with different counts (e.g., \"associated with\") strongly suggest issues with how relationships are identified and aggregated across chunks. A larger chunk size could exacerbate this. If a single 100-token chunk contains two instances of a character being \"associated with\" different things, and another chunk also contains \"associated with\" instances, the aggregation process might struggle to differentiate them, leading to duplicated or ambiguously counted relationships. Smaller chunks would likely result in more distinct relationship instances, simplifying aggregation",
  "graph_builder_agent_critique": "Here's a critique of the graph construction prompt and resulting graph, focusing on improvements for a GraphRAG system:\n\n**Critique of Graph Construction Prompt & Resulting Graph:**\n\n1.  **Overly Generic Entity/Relationship Extraction:**\n    *   **Issue:** The prompt requests \"entities\" and \"relationships\" but lacks specific instructions for *what kind* of entities and relationships are most valuable for a RAG system. This leads to the observed abundance of generic relationship types like \"associated with\" (appears multiple times with different counts) and broad entity types like \"Concept\" and \"Object.\"\n    *   **Impact:** These generic labels create noise and reduce the precision of graph exploration. The LLM agent has to sift through many irrelevant or vague connections to find meaningful information. For instance, \"associated with\" doesn't tell the agent *how* entities are associated (e.g., is it a cause, an effect, a possession, a collaboration?).\n    *   **Suggestion:** The prompt should guide the LLM to identify *semantically rich* entities and relationships relevant to narrative or factual extraction. For relationships, it should encourage more specific types like \"causes,\" \"enables,\" \"located in,\" \"protagonist of,\" \"conflict with,\" \"developed by,\" \"discovered during,\" etc. For entities, it should encourage sub-typing where appropriate (e.g., distinguishing between a \"scientific concept\" and a \"narrative theme\").\n\n2.  **Lack of Explicit Role/Function Specification:**\n    *   **Issue:** The prompt asks for entity properties but doesn't emphasize identifying the *role* or *function* of entities within the text.\n    *   **Impact:** Knowing a person is a \"character\" is less useful than knowing they are the \"protagonist,\" \"antagonist,\" or \"mentor.\" Similarly, knowing an \"Object\" is a \"weapon\" is better than just \"object.\"\n    *   **Suggestion:** Add explicit instructions to identify and capture the functional role or significance of entities. For example: \"For each entity, also identify its role or function within the context of the text (e.g., protagonist, antagonist, McGuffin, scientific theory, historical event).\"\n\n3.  **Inconsistent Aggregation/Counting:**\n    *   **Issue:** The graph description shows duplicated relationship types with different counts (e.g., \"associated with\" appears with counts 8 and 3). This indicates an issue",
  "retrieval_planner_agent_critique": "The retrieval plan exhibits a significant issue with **redundant exploration**, particularly in the repeated use of `search_nodes_by_keyword('Gurn')`. After the initial discovery of the 'Gurn' node, subsequent plans should leverage `get_neighbors` or more specific relationship searches rather than re-querying the same keyword. Iterations 2 and 5 are also problematic as they both aim to explore Gurn's connections without a clear strategic difference, suggesting a lack of progress tracking.\n\nThe plan also suffers from **lack of strategic depth and missed opportunities for graph traversal**. For example, after identifying neighbors in Iteration 2, the plan doesn't prioritize digging deeper into specific, promising relationships (e.g., exploring the \"leader of\" relation with Vasads further). Instead, it resorts to broader searches or revisiting similar exploration. There's also no apparent strategy to explore beyond direct neighbors (e.g., two-hop connections) or to utilize functions like `identify_communities` or `analyze_path` to understand Gurn's position or influence in the broader graph.\n\nFinally, the **iteration logic is suboptimal**. Iteration 4's decision to search for 'Gurn' again after already exploring its neighbors indicates a failure to consolidate information and use it to guide the next step. The system should aim to expand outwards from discovered information rather than revisiting already covered ground without a new hypothesis. The plan would benefit from explicitly tracking explored nodes/relationships and using that to inform the next, more targeted step.",
  "answer_generation_critique": "The provided example highlights several weaknesses in the current prompt's ability to elicit a well-structured and focused answer. The core issue is that the prompt is too general and doesn't guide the LLM to synthesize information effectively or prioritize relevant details based on the query.\n\nHere's a breakdown of the critique and suggestions for prompt improvement:\n\n**1. Lack of Structure and Prioritization Guidance:**\n\n*   **Issue:** The prompt instructs the LLM to \"use the retrieved context to answer the query\" but doesn't specify *how* to structure that answer. This leads to a list-like output where important information (like leadership) is presented alongside minor details (like a girl's inquiry).\n*   **Impact:** The answer becomes unfocused and difficult to digest, failing to clearly articulate Gurn's *role*.\n*   **Prompt Improvement:** Introduce instructions for structuring the answer. For example: \"Prioritize information to clearly define the subject's primary role, then elaborate on supporting details, relationships, and key actions. Start with the most significant aspect of the role.\"\n\n**2. Insufficient Guidance on Synthesizing and Elaborating:**\n\n*   **Issue:** The prompt asks the LLM to \"exploit the retrieved information, even if incomplete,\" but doesn't encourage synthesis or explanation. The LLM simply lists extracted facts.\n*   **Impact:** Ambiguous phrases like \"father's woman\" and \"revealing his new identity\" remain unexplained because the prompt doesn't push the LLM to clarify or infer based on context, or to explicitly state what information is missing.\n*   **Prompt Improvement:** Add directives for synthesis and clarification. For example: \"Synthesize the retrieved information to provide a coherent narrative. If terms or relationships are ambiguous in the context, try to clarify them or note the ambiguity.\"\n\n**3. Lack of Focus on \"Role\":**\n\n*   **Issue:** The prompt is generic (\"answer the query\") and doesn't specifically emphasize understanding and explaining the *role* of the entity in question.\n*   **Impact:** The LLM includes information that is tangential to Gurn's role (e.g., what a girl inquired about).\n*   **Prompt Improvement:** Explicitly direct the LLM to focus on the \"role.\" For example: \"Your primary objective is to define and explain the *role* of the subject mentioned in the query. Focus on their position, responsibilities, key",
  "graph_builder_prompt": "\nYou will be given a text. Your goal is to identify entities in the text and all the relationships among the identified entities.\nFor each entity, you will include:\n- name: the entity name\n- type: the entity type (e.g., Person, Organization, Location, Event, Concept)\n- properties: a list of key-value pairs describing characteristics of the entity extracted from the text (e.g., for a person: age, role, description; for a location: description, significance). Each property should have a \"key\" and \"value\" field.\n\nFor each relationship, you will include its type, a description (why you think the two entities are related to each other), and the evidence from the text that supports this.\nThe relationships must be among the extracted entities.\nProvide a list of triplets in your answer.\n\nReturn no more than 20 entities and 30 relationships. \n\nText:\n{TEXT_CHUNK}\n\nProvide the reasoning that led to your response.\n",
  "retrieval_prompt": "\nYour goal is to decide the next step of a strategy to explore a graph in order to retrieve relevant information to answer the following query: What is Gurn's role in the story?.\n\nA high-level description of the graph is the following: This graph contains 201 nodes and 424 relationships. The graph density is 0.0211, indicating a sparsely connected network. The graph is fully connected with a fragmentation index of 0.0000. The most frequent entity types are 78 \"Location\"s, 49 \"Person\"s, 26 \"Concept\"s, 14 \"Object\"s, 7 \"Organization\"s, 5 \"Group\"s, 5 \"Weapon\"s, 3 \"Deity\"s, 3 \"Event\"s, 2 \"Clothing\"s, 2 \"Food & Drink\"s, 1 \"Animal\", 1 \"Body Part\", 1 \"Celestial Body\", and 1 \"Liquid\". The most frequent relationship types are 8 \"associated with\" relationships, 7 \"attacks\" relationships, 5 \"inhabits\" relationships, 4 \"attacks\" relationships, 4 \"approaches\" relationships, 4 \"contains\" relationships, 4 \"interacts with\" relationships, 4 \"observes\" relationships, 4 \"possesses\" relationships, 4 \"wears\" relationships, 3 \"associated with\" relationships, 3 \"communication\" relationships, 3 \"destination\" relationships, 3 \"is a\" relationships, and 3 \"is in\" relationships.\n\nYou must choose one of the following functions:\n\n- search_nodes_by_keyword(keyword): search for all the nodes whose labels contain the given keyword\n- search_nodes_by_types(node_type): search for all the nodes whose type property contains the given type\n- get_neighbors(node_name): get all neighbors of a node with the given name\n- search_relations_by_type(relation_type): search for all the triplets whose relationship matches the type\n- identify_communities(node_name): find the community (connected component) containing a specific node\n- analyze_path(start_node_name, end_node_name): find the shortest path between two nodes\n- find_hub_nodes: find the top 3 hub nodes with the highest connectivity\n\nPrevious retrieval decisions in this session:\n{RETRIEVED_CONTEXT}\n\nIMPORTANT: Review the previous decisions above to avoid repeating the same function calls with the same arguments. Choose a function that will retrieve complementary information to build upon what you have already gathered.\n\nChoose one of the functions and specify the arguments.\n\nProvide the reasoning that led to your response.\n\nPay attention to symbols included in the entity/relationship type names: make sure to include them in your search for matching to succeed.\nAlso, pay attention to symbols included in the functions names. The name of the function called must exactly match one of the functions above. \n"
}