{
  "learned_prompt_hyperparameters_graph": "You are an AI assistant specializing in optimizing GraphRAG systems. Your task is to analyze provided text and recommend optimal hyperparameters for knowledge graph construction, with a primary focus on **chunk size**.\n\nWhen determining the optimal chunk size, consider the following critical factors, derived from analysis of entity resolution and relationship extraction challenges:\n\n1.  **Entity Resolution Context:** A chunk must contain enough surrounding text to disambiguate entities. Prioritize chunk sizes that maximize the likelihood of all mentions of a key entity (characters, locations, organizations, etc.) appearing within a single chunk. This helps resolve ambiguities like \"Priest\" vs. \"Priest of the Skull\" or variations in names like \"Tholon Sarna\" vs. \"Sarna.\"\n\n2.  **Relationship and Action Completeness:** Chunk boundaries should ideally not fragment crucial relationships and actions. Aim for chunk sizes that allow for the complete description of connections (e.g., `GURN -IS_SIBLING_OF-> THOLON_SARNA`, `GURN -HAS_LOYAL_GROUP-> VASADS`). Fragmented descriptions lead to incomplete graph structures and require speculative inference.\n\n3.  **Information Specificity vs. Generality:** While some general context is necessary, chunks should primarily focus on consolidating specific, relevant information. A larger chunk size can help group related factual details, making them more prominent for graph construction. Avoid chunk sizes that excessively dilute specific facts with broad, less relevant narrative. However, also consider that excessively large chunks might dilute specific information if they contain too much unrelated narrative.\n\n**Task:**\n\nBased on the text provided, propose an optimal chunk size (in tokens). Justify your recommendation by explaining how the chosen size addresses the above factors. Suggest a range (e.g., 200-400 tokens) if a single value is uncertain, and explain the trade-offs. You will also be asked to suggest other relevant hyperparameters if the text provides sufficient context.\n\nYour goal is to recommend parameters that facilitate the creation of a well-connected, accurate, and informative knowledge graph from the given text. Begin by analyzing the text and proposing the chunk size.",
  "learned_prompt_answer_generator_graph": "You are an AI assistant tasked with answering questions based on retrieved graph information. Your goal is to synthesize this information into a coherent, concise, and insightful answer.\n\n**Instructions for Answering:**\n\n1.  **Prioritize Core Narrative Role:** Clearly identify and articulate the character's primary function, most impactful contributions, and significant motivations within the narrative.\n2.  **Be Concise and Direct:** While maintaining depth, aim for brevity. Avoid unnecessary jargon, speculation, or tangential details. Focus on information directly supported by the retrieved data.\n3.  **Handle Obscure Information Prudently:** If retrieved information appears tangential, obscure, or is not clearly linked to the character's central role, omit it or mention it *only* if it directly supports a core aspect. Do not elaborate extensively on unconfirmed or minor details.\n4.  **Structure for Clarity:**\n    *   Begin by stating the character's primary role or function in the story.\n    *   Elaborate on key supporting elements: significant motivations, core relationships, and defining actions.\n    *   Conclude by summarizing their overall impact on the narrative.\n5.  **Synthesize and Avoid Redundancy:** Connect related pieces of information logically. Ensure each sentence adds new, distinct information or elaborates on a previous point without directly repeating stated facts.\n6.  **Maintain Factual Accuracy:** Base your answer strictly on the provided retrieved information. If the information is incomplete, state that or focus on what is clearly known. Avoid making assumptions or introducing outside knowledge.\n\n**Answer Format:**\n\n*   Provide a well-structured, narrative answer.\n*   Ensure smooth transitions between points.\n*   Focus on delivering the most relevant information efficiently.",
  "learned_prompt_graph_retrieval_planner": "You are a highly intelligent agent tasked with selecting the most relevant communities from a knowledge graph to answer a user's query. Your primary goal is to identify communities that *directly* contribute information about the specific entities and concepts mentioned in the query.\n\nWhen evaluating communities for relevance to the query, adhere to the following principles:\n\n1.  **Prioritize Direct Entity Mentions:** Give highest importance to communities that explicitly mention the key entities from the query. For the query \"[QUERY_ENTITY]\", seek communities that directly discuss \"[QUERY_ENTITY]\", its actions, relationships, attributes, or status.\n\n2.  **Enforce Granular Relevance:** Do not select communities based on superficial keyword matches or broad thematic similarities alone. The content of a community must specifically illuminate aspects of the query entity or concept. For \"[QUERY_ENTITY]\", assess *how* each community's information helps define their role, actions, or significance. Generic mentions of related concepts (e.g., \"warriors\" when the query is about a specific warrior) are insufficient if \"[QUERY_ENTITY]\" is not directly involved.\n\n3.  **Discourage Tangential or Ambiguous Links:** Avoid selecting communities where connections are indirect, ambiguous, or based on weakly associated terms. If a community mentions a related term but does not clearly link it to the query entity in a meaningful way, do not select it. For example, if a community mentions a character with a similar name but distinct identity, do not include it if it doesn't clarify the query entity.\n\n4.  **Focus on Role-Defining Information:** Actively seek communities that describe the query entity's \"role, actions, relationships, motivations, or status.\" Information that directly answers \"What is X's role?\" or describes X's specific involvement is paramount.\n\n5.  **Identify and Justify Selection:** For each community you select, provide a concise justification explaining *why* it is relevant to the query, specifically referencing how it directly addresses the query entity and its role.\n\n**Example Query:** \"What is Gurn's role in the story?\"\n\n**Selection Strategy:**\n*   Prioritize communities explicitly mentioning \"Gurn\".\n*   Look for descriptions of Gurn's relationships (e.g., with Tholon Sarna, Noork), his actions (e.g., exile, companionship), or his status.\n*   Reject communities that only mention generic terms like \"temple,\" \"conflict,\" or \"warriors\" without a direct link to Gurn's specific role or involvement.\n*   Be wary of communities mentioning similarly named entities (e.g., different \"Sarna\" individuals) that could cause confusion.\n\nYour task is to present a list of community IDs that strictly adhere to these guidelines, ensuring that the retrieved information will directly and accurately answer the user's query.",
  "learned_prompt_graph_builder": "You are an AI assistant tasked with constructing a knowledge graph from provided text. Your goal is to extract entities, their dynamic properties, and the actions and relationships connecting them to build a rich, interconnected graph that captures narrative depth.\n\nWhen processing text, identify the following:\n\n1.  **Entities:** Recognize key people, places, organizations, and significant concepts.\n    *   Format: `entities: [{ id: \"unique_entity_name\", type: \"PERSON\" | \"LOCATION\" | \"ORGANIZATION\" | \"CONCEPT\", name: \"Full Entity Name\" }]`\n\n2.  **Actions & Events:** Identify specific actions taken by entities, their motivations, and the narrative consequences or goals.\n    *   Format: `actions: [{ actor_id: \"entity_id\", verb: \"action_verb\", object_id: \"entity_id_or_text\", description: \"Brief narrative description of the action and its purpose/outcome\", motivation: \"Why the action was taken (if stated/implied)\", goal: \"What the action aimed to achieve (if stated/implied)\" }]`\n\n3.  **Relationships:** Define connections between entities, emphasizing their nature and implications.\n    *   Format: `relationships: [{ source_id: \"entity_id\", target_id: \"entity_id\", type: \"RELATIONSHIP_TYPE\", description: \"Nature of the relationship and its implications (e.g., loyalty, rivalry, alliance)\", inferred: true | false }]`\n    *   Note: If an entity is loyal or affiliated, describe the *implications* of this loyalty/affiliation. Mark as `inferred: true` if not explicitly stated but strongly implied.\n\n4.  **Properties:** For each entity, capture essential characteristics, with a focus on dynamic attributes like roles, goals, decisions, and narrative significance of statuses.\n    *   Format: `properties: [{ entity_id: \"entity_id\", key: \"property_key\", value: \"property_value\" }]`\n    *   Examples of `property_key`: `status`, `motivations`, `decisions`, `narrative_significance`, `goals`, `strategic_positioning`, `affiliations`.\n    *   For statuses (e.g., \"exile\"), describe their *narrative impact* or how they influence actions/motivations.\n\n**Prioritization:**\n\n*   Prioritize actions and motivations that drive the narrative.\n*   Capture implied relationships and their strategic importance.\n*   Synthesize the narrative function of entity statuses.\n\n**Output Structure:**\n\nProduce a single JSON object containing the `entities`, `actions`, `relationships`, and `properties` arrays. Ensure all `entity_id` references within actions, relationships, and properties accurately correspond to the `id` fields in the `entities` array. Avoid redundancy; if an action implies a relationship, ensure both are captured accurately.",
  "learned_prompt_hyperparameters_vector": "",
  "learned_prompt_answer_generator_vector": "",
  "learned_prompt_vector_retrieval_planner": "",
  "hyperparameters_graph_agent_critique": "The current chunk size of 100 appears to be a significant contributing factor to the identified issues in the knowledge graph.\n\n**Critique of Chunk Size 100:**\n\n1.  **Insufficient Context for Entity Resolution:** A chunk size of 100 tokens is likely too small to capture sufficient contextual information for robust entity resolution. The critique highlights the confusion between \"Tholon Sarna\" and \"Sarna,\" and \"Priest\" and \"Priest of the Skull.\" These instances suggest that the surrounding text within a 100-token chunk might not consistently provide enough disambiguating information to link identical entities or differentiate distinct ones. Larger chunks would increase the probability of encountering all mentions of a character or role within a single piece of text, aiding in their unification.\n\n2.  **Fragmented Relationships and Actions:** The critique emphasizes the need for explicit, typed relationships (e.g., `GURN -IS_SIBLING_OF-> THOLON_SARNA`, `GURN -HAS_LOYAL_GROUP-> VASADS`). Small chunks can break apart these relationships. For instance, a sentence describing Gurn's loyalty to Vasads might be split across two chunks, or the description of Gurn's companion status might be separated from the mention of Noork. This fragmentation forces the graph extraction to infer relationships from incomplete data, leading to ambiguity or missed connections.\n\n3.  **Over-Inclusion of General Context (and potential under-inclusion of specific context):** While the critique suggests some communities contain too much general context, a small chunk size can also *prevent* the system from identifying and prioritizing *specific*, relevant context. If crucial details about Gurn's role or actions are spread across many small, disconnected chunks, the graph extraction might dilute these specific facts with broader narrative elements present in other chunks. Conversely, if a chunk *only* contains general world-building text, it contributes to the \"over-inclusion\" problem without offering specific, query-relevant information. A larger chunk size could help group related specific details together, making them more prominent during graph construction.\n\n**Recommendation:**\n\nIncreasing the chunk size is strongly recommended. A larger chunk size (e.g., 200-400 tokens) would likely:\n*   Improve entity resolution by providing more surrounding text for disambiguation.\n*   Allow for the capture of more complete relationships and actions within single chunks.\n*   Help in consolidating specific, relevant information and potentially filtering out less relevant narrative details if the larger chunks are more cohesive.\n\nThe goal is to find a balance where chunks are large enough to contain meaningful context for entity and relationship extraction but not so large as to become unwieldy or dilute specific information with excessive narrative.",
  "graph_builder_agent_critique": "Here's a critique of the provided graph construction prompt, focusing on its limitations in capturing nuanced character roles and inter-community connections, with recommendations for improvement:\n\n**Critique of Graph Construction Prompt:**\n\n1.  **Overemphasis on Explicit Relationships, Underemphasis on Actions/Motivations:** The prompt heavily focuses on identifying entities and their explicit relationships (\"relationships among the identified entities\"). While crucial, this approach often leads to a static representation. For example, Gurn is defined by his relationships (brother, companion) and status (exile) rather than his actions or motivations. The prompt doesn't explicitly ask for verbs or actions that describe *what* entities do or *why*.\n\n2.  **Shallow \"Properties\" Field:** The \"properties\" field, while intended to describe characteristics, is often populated with descriptive phrases or simple affiliations (e.g., \"companion to Noork\"). It lacks a directive to capture a character's *agency*, *goals*, or *decisions*, which are vital for understanding their \"role.\" The prompt could be more specific about what kinds of properties are desired, such as \"actions taken,\" \"decisions made,\" or \"stated motivations.\"\n\n3.  **Limited Implicit Connection Handling:** The prompt's structure for relationship extraction is primarily pairwise and explicit. It struggles to capture implicit connections or the *implications* of relationships. The loyalty of \"Vasads to Gurn\" is noted but not explored for its strategic importance or Gurn's potential influence. The prompt doesn't encourage inferring connections based on context across different text segments.\n\n4.  **Weak Linkage of Status to Narrative Function:** Gurn's status as an \"exile from Grath\" is extracted but its narrative significance or how it might inform his actions and role is not emphasized by the prompt. The prompt needs to guide the LLM to consider how statuses might influence behavior or plot.\n\n5.  **Lack of Focus on \"Role\" Synthesis:** The prompt asks for \"entities\" and \"relationships,\" but the subsequent community summarization and retrieval are where \"role\" synthesis is needed. The graph extraction itself should ideally lay a better foundation for this synthesis by capturing more dynamic information. The current prompt, by focusing on static attributes, makes it harder for downstream components to answer a query about \"role.\"\n\n**Recommendations for Prompt Improvement:**\n\n1.  **Incorporate Action-Oriented Extraction:** Modify the prompt to explicitly ask for extracted \"actions\" or \"events\" associated with entities. For example, a new category could be `actions: [{ verb: \"commands\", object: \"Vasads\", description: \"Gurn orders the Vasads.\" }]`.\n\n2.  **Refine \"Properties\" to Include Agency:** Expand the definition of \"properties\" to encourage capturing dynamic traits. Suggest properties like `motivations: \"Seeking redemption.\"`, `decisions: \"Chose to exile himself.\"`, `strategic_positioning: \"Leverages loyalty of Vasads.\"`.\n\n3.  **Prompt for Inferred or Contextual Relationships:** Add a directive to identify and describe *potential* or *implied* relationships, especially where loyalty or affiliation is mentioned. Include instructions like \"If an entity is loyal to another, consider what actions or influence this loyalty implies and document them.\"\n\n4.  **Emphasize Narrative Significance of Statuses:** When extracting properties or relationships, prompt the LLM to consider *why* a status is relevant. For instance, for \"exile,\" prompt to look for connections like \"exile from X led to Y action\" or \"exile from X influences Z motivation.\"\n\n5.  **Add a \"Role/Function\" Field (Optional but beneficial):** Consider a top-level field for key entities that explicitly asks for their narrative role, if strongly indicated in the text. This could be a short, synthesized statement derived from their actions and relationships.\n\nBy integrating these changes, the graph construction prompt can produce richer, more dynamic knowledge graphs that better support complex queries about character roles and implicit narrative connections.",
  "retrieval_planner_agent_critique": "Here's a critique of the community selection process for the query \"What is Gurn's role in the story?\":\n\nThe current community selection prompt and the agent's execution demonstrate a significant weakness in granular relevance assessment and a tendency towards over-generalization, leading to the inclusion of noisy and tangential information.\n\n**Key Issues:**\n\n1.  **Superficial Keyword Matching:** The agent appears to rely too heavily on keywords and broad thematic similarities rather than direct relevance to the query entity, \"Gurn.\"\n    *   **Community 0** is correctly identified because it *explicitly* mentions Gurn, his relationship to Tholon Sarna, and his association with Noork. This is the crucial element of direct relevance.\n    *   **Community 7** is selected due to the mention of \"Sarna,\" but this \"Sarna\" is specified as \"daughter of Tholon Dist,\" creating ambiguity and a false connection to Tholon Sarna (Gurn's sister) from Community 0. The selection overlooks the critical difference in identity and the lack of any mention of Gurn.\n    *   **Communities 8, 9, and 10** are selected based on general themes like \"temple,\" \"conflict,\" and \"warriors.\" These are far too generic. The summaries do not contain any mention of Gurn or any specific actions or relationships that would shed light on *his* role. For instance, \"warriors\" in Community 10 offers no specific information about Gurn.\n\n2.  **Lack of Prioritization of Direct Character Information:** The prompt did not sufficiently guide the agent to prioritize information that *directly* describes Gurn's actions, relationships, or status (e.g., \"exile from Grath,\" \"companion\" to Noork, \"brother\" to Tholon Sarna, as provided in Community 0). Instead, it allowed for the inclusion of communities with only distant or implied connections.\n\n3.  **Introduction of Ambiguity and Distraction:** The inclusion of Community 7, with its potentially confused \"Sarna\" reference, directly hinders precise entity resolution. The other selected communities (8, 9, 10) add noise and distract the subsequent answer generation LLM with irrelevant details about temple hierarchy or generic combat scenarios.\n\n**Recommendations for Improvement:**\n\n1.  **Strengthen Direct Entity Mentions:** Explicitly instruct the agent to prioritize communities that *name* the query entity (Gurn) or describe his direct actions, relationships, or attributes.\n2.  **Enforce Granular Relevance:** The prompt should guide the agent to assess *how* each community's content specifically contributes to understanding \"Gurn's role.\" A low bar like \"mentions warriors\" is insufficient.\n3.  **Discourage Tangential Thematic Links:** Clearly state that general themes or loosely associated keywords are not sufficient justification for selection if the query entity is not directly involved.\n4.  **Prioritize Role-Defining Information:** The prompt could ask the agent to consider if a community describes Gurn's \"actions, relationships, motivations, or status.\"\n\nBy refining the prompt to emphasize direct relevance and character involvement, the agent can be steered towards selecting only the most pertinent communities, such as Community 0, leading to a more focused and accurate answer.",
  "answer_generation_critique": "The previous answer generation prompt was effective in guiding the LLM to synthesize information and provide depth. However, the generated answer revealed several areas for improvement, primarily related to **conciseness, focus, and handling of potentially extraneous details.**\n\n**Critique of the Previous Prompt and Suggestions for Improvement:**\n\n1.  **Overly Broad Instructions Leading to Wordiness:**\n    *   **Issue:** The prompt's emphasis on \"comprehensive and insightful,\" \"depth and elaboration,\" and \"contextualize information\" led to explanations that were sometimes wordy and speculative (e.g., \"This exile status *might* inform his motivations...\"). While comprehensive is good, it can sometimes lead to including less critical information or phrasing things indirectly.\n    *   **Suggestion:** Introduce a specific instruction to prioritize **\"core narrative role\"** and **\"most impactful contributions.\"** Add a directive to be **\"concise and direct\"** when possible, while still maintaining depth. Consider explicitly stating that speculative phrasing should be avoided if the information isn't directly supported.\n\n2.  **Handling of Tangential or Unclear Information:**\n    *   **Issue:** The prompt instructed to \"handle incomplete information\" and \"focus on relevance.\" However, the generated answer included the \"New York\" connection, which was obscure and detracted from Gurn's primary role, suggesting the prompt didn't sufficiently guide the LLM on *how* to discern and handle such details.\n    *   **Suggestion:** Enhance the prompt with a guideline like: \"If a piece of retrieved information seems tangential, obscure, or is not clearly linked to the character's primary role or motivations within the narrative, prioritize omitting it or briefly mentioning it only if it directly supports a core aspect of their role. Avoid extensive speculation on such details.\"\n\n3.  **Lack of Explicit Prioritization within the Answer Structure:**\n    *   **Issue:** The prompt outlined several aspects to focus on (actions, motivations, relationships, impact), but it didn't explicitly guide the LLM to *start* with the most defining aspects of the character's role and then elaborate. The current answer introduced Gurn and then immediately jumped to his sister, which is good, but could be structured more deliberately.\n    *   **Suggestion:** Refine the \"Instructions for Answering\" to suggest an order or hierarchy. For example: \"Begin by clearly stating the character's primary function or role in the story. Then, elaborate on the key elements supporting this role, such as their most significant motivations, relationships, and actions. Conclude by summarizing their overall impact.\"\n\n4.  **Potential for Redundancy:**\n    *   **Issue:** The prompt's general instruction to \"Synthesize Information\" and \"Connect related pieces of information\" is generally good, but without a specific check for direct repetition, it can lead to sentences that restate the same idea (e.g., \"Gurn's actions and motivations are directly linked to this rescue mission\" after already establishing the connection).\n    *   **Suggestion:** Add a meta-instruction like: \"Ensure each sentence adds new information or elaborates on a previous point without direct repetition of already stated facts.\"\n\nIn summary, the prompt needs to be more directive about **prioritization, conciseness, and judicious inclusion/exclusion of information**, especially when that information is not clearly central to the character's defined role. This will help the LLM generate answers that are more focused and impactful, leading to better ROUGE scores and a more efficient retrieval system.",
  "graph_builder_prompt": "\nYou will be given a text. Your goal is to identify entities in the text and all the relationships among the identified entities.\nFor each entity, you will include:\n- name: the entity name\n- type: the entity type (e.g., Person, Organization, Location, Event, Concept)\n- properties: a list of key-value pairs describing characteristics of the entity extracted from the text (e.g., for a person: age, role, description; for a location: description, significance). Each property should have a \"key\" and \"value\" field.\n\nFor each relationship, you will include its type, a description (why you think the two entities are related to each other), and the evidence from the text that supports this.\nThe relationships must be among the extracted entities.\nProvide a list of triplets in your answer.\n\nReturn no more than 20 entities and 30 relationships. \n\nText:\n{TEXT_CHUNK}\n\nProvide the reasoning that led to your response.\n",
  "retrieval_prompt": "\nYou are an agentic retrieval component of a community-based GraphRAG system. Your goal is to select the most relevant communities from the knowledge graph to answer the following query: What is Gurn's role in the story?.\nYou can select more than one community. \n\nAvailable Communities:\n{RETRIEVED_CONTEXT}\n\nSelect the communities that are most relevant to answering the query. Choose communities that together provide comprehensive coverage of the information needed.\n\nProvide the list of community IDs you want to retrieve and explain your reasoning for selecting these specific communities.\n"
}