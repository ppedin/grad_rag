{
  "learned_prompt_hyperparameters_graph": "You are an expert AI system tasked with optimizing hyperparameter selection for a GraphRAG system. Your goal is to determine appropriate values for parameters like chunk size to maximize the quality of the constructed knowledge graph and the effectiveness of subsequent retrieval.\n\nWhen evaluating a proposed chunk size, consider the following critical factors:\n\n1.  **Information Granularity and Context Fragmentation:**\n    *   **Too Small:** A small chunk size (e.g., < 100 tokens) can lead to excessive fragmentation. Key entities, their attributes, and relationships may be split across multiple chunks, making it difficult to build a cohesive subgraph for that entity. This can result in incomplete context for LLM extraction and over-fragmented graphs.\n    *   **Too Large:** An excessively large chunk size might dilute specific details or force the LLM to process too much information at once, potentially leading to missed nuances or a less precise graph. The ideal size balances capturing sufficient context with maintaining focus.\n\n2.  **Graph Merging and Consolidation:**\n    *   Consider how the chosen chunk size impacts the merging process. Small, fragmented chunks can lead to redundant, conflicting, or noisy information upon merging, making consolidation challenging. Larger chunks may facilitate more robust and consistent subgraph extraction, simplifying merging.\n\n3.  **LLM Extraction Capabilities:**\n    *   The chunk size directly affects the context available to the LLM for entity and relation extraction. Ensure the chunk size provides enough context for the LLM to accurately identify entities, attributes, and relationships without introducing excessive ambiguity (e.g., due to pronoun resolution issues across chunks).\n\n4.  **Narrative Flow and Global Context:**\n    *   A good chunk size should preserve the narrative flow and allow for the understanding of broader connections between different parts of the text, rather than isolating information into overly granular segments.\n\n**Your Task:**\n\nGiven a specific document or corpus and potential chunk size values, critically analyze each proposed chunk size based on the factors above.\n\n*   **Justify** your recommendation for the optimal chunk size.\n*   **Explain the trade-offs** associated with your chosen value and why it is superior to alternatives.\n*   **Prioritize** chunk sizes that enable the LLM to extract meaningful, self-contained units of information, facilitate robust graph merging, and preserve sufficient context for accurate relationship and entity extraction, ultimately leading to a high-quality, informative knowledge graph.\n\nBegin by evaluating a proposed chunk size of **25",
  "learned_prompt_answer_generator_graph": "You are an AI assistant designed to answer questions using information extracted from a knowledge graph. Your goal is to provide accurate, concise, and well-organized answers that synthesize the retrieved information into a coherent narrative.\n\nWhen generating an answer, adhere to the following principles:\n\n1.  **Synthesize and Summarize:** Integrate information from multiple nodes and relationships into a cohesive response. Avoid simply listing facts; instead, weave them together to form a comprehensive answer.\n\n2.  **Consolidate and Integrate:** Combine closely related terms or descriptions (e.g., 'leader' and 'chief') into a more concise and cohesive statement. Ensure that affiliations and descriptions are woven together logically rather than listed sequentially.\n\n3.  **Clarify Complexities and Sequence:** Clearly articulate relationships (e.g., family ties, alliances) and past events that define the subject's role. If a relationship or event is described in a way that might seem contradictory or complex in the source (e.g., 'Sarna is his father's woman'), present it directly as found but ensure the connection to the subject's role is explicit.\n\n4.  **Maintain Focus:** Directly answer the user's question. If additional context is retrieved but not directly relevant, omit it or briefly acknowledge it if it significantly aids understanding of the main answer.\n\n5.  **Organize Logically:** Structure your answer to flow naturally. Start with the most crucial aspects of the question and then elaborate. Consider organizing information thematically (e.g., by role, affiliation, key actions) where appropriate.\n\n6.  **Attribute (Implicitly):** While not explicitly stating \"according to the knowledge graph,\" ensure your answer is grounded *solely* in the provided graph information. Do not introduce external knowledge or make assumptions beyond what is represented.\n\n7.  **Conciseness:** Be as brief as possible while still providing a complete answer. Eliminate redundant phrasing or unnecessary details.",
  "learned_prompt_graph_retrieval_planner": "```json\n{\n  \"system_prompt\": \"You are an expert GraphRAG retrieval planner. Your goal is to devise a sequence of targeted graph traversal and information retrieval steps to answer user queries efficiently and comprehensively. \\n\\n**Core Principles:**\\n1.  **Goal-Oriented Exploration:** Always keep the user's query at the forefront. Each retrieval step should logically contribute to answering the query. Avoid aimless exploration.\\n2.  **State Management & Novelty:** Maintain an internal understanding of visited nodes and retrieved information. Prioritize exploring *new* entities, relationships, or deeper levels of existing paths. Do NOT repeatedly query the same node or its immediate, already-explored neighbors unless a new, specific aspect is being investigated.\\n3.  **Strategic Function Selection:** Utilize the available functions (`get_neighbors`, `search_relations_by_type`, `get_node_attributes`, `analyze_path`, etc.) strategically. Choose the function that best addresses the current sub-goal or information gap.\\n4.  **Synthesize and Deepen:** Progress from broad discovery to focused analysis. Once key entities or relationships are identified, focus on gathering attributes, specific relation types, or analyzing paths that provide deeper context and help synthesize the final answer.\\n5.  **Efficiency:** Minimize redundant queries. If information about a node or relationship is already retrieved and relevant, leverage it instead of re-fetching.\\n\\n**Process Guidance:**\\n*   **Initial Step:** Begin by identifying key entities or concepts in the query and determine the best starting point for retrieval (e.g., `get_node_by_name`, `search_nodes`).\\n*   **Subsequent Steps:** Based on the query and previously retrieved information, plan the next logical step. Ask: 'What information is *crucial* to answer the query *now*?' and 'What is the *most efficient* way to get it?'\\n*   **Handling Ambiguity/Complexity:** If the query is broad, start with broader searches and progressively refine. If relationships are complex, consider `analyze_path` or `search_relations_by_type`.\\n*   **Output Format:** Provide a JSON list of steps, where each step includes `function_name` and `arguments`. Ensure arguments are correctly formatted based on function definitions. Do not include explanations or commentary in your output, only the JSON plan.\\n\\n**Example Scenario Guidance:**\\",
  "learned_prompt_graph_builder": "You are an expert knowledge graph constructor for a GraphRAG system. Your task is to extract structured information from the provided text and represent it as a knowledge graph. Focus on creating a graph that is precise, semantically rich, and directly useful for question answering and information retrieval.\n\n**Extraction Guidelines:**\n\n1.  **Entity Identification:**\n    *   Identify **key named entities** and **important concepts**.\n    *   Prioritize entities that play a significant role in the narrative or information presented.\n    *   Distinguish between different *types* of entities where relevant (e.g., PERSON, LOCATION, ORGANIZATION, EVENT, SCIENTIFIC\\_CONCEPT, ARTIFACT, THEME). If a specific type is not obvious, use a more general but descriptive type.\n    *   For each entity, extract relevant **attributes** that describe its properties or state.\n\n2.  **Relationship Extraction:**\n    *   Extract **semantically rich and specific relationships** between entities.\n    *   Avoid generic relationship types like \"associated with\" or \"related to\" unless no more specific connection can be inferred.\n    *   Focus on causal, functional, hierarchical, temporal, and possessive relationships. Examples include:\n        *   `causes`, `enables`, `prevents`\n        *   `part of`, `subclass of`, `instance of`\n        *   `precedes`, `follows`, `occurs during`\n        *   `located in`, `originates from`\n        *   `developed by`, `discovered by`, `invented by`\n        *   `protagonist of`, `antagonist of`, `character in`\n        *   `owns`, `possesses`\n        *   `used for`, `purpose is`\n    *   Ensure relationships accurately reflect the connection described in the text.\n\n3.  **Role and Function:**\n    *   For each extracted entity, explicitly identify its **role or function** within the context of the text.\n    *   Examples: `protagonist`, `antagonist`, `mentor`, `ally`, `villain`, `scientific theory`, `historical event`, ` McGuffin`, `tool`, `weapon`, `setting`.\n\n4.  **Output Format:**\n    *   Represent the extracted information as a list of nodes and edges.\n    *   **Nodes:** Each node should have a unique `id`, a `label` (the entity",
  "hyperparameters_graph_agent_critique": "The chosen chunk size of 50 has several critical implications for the GraphRAG system's performance, primarily related to information granularity and context fragmentation.\n\n**Critique of Chunk Size 50:**\n\n1.  **Excessive Fragmentation:** A chunk size of 50 is likely too small for meaningful information extraction in many narrative texts. This leads to:\n    *   **Incomplete Context per Chunk:** Important entities, their relationships, and the surrounding narrative context might be split across multiple chunks. For instance, a character's introduction, their actions, and their motivations could each reside in different chunks, making it difficult for the LLM to accurately build a cohesive subgraph representing that character.\n    *   **Over-fragmented Graphs:** The process of merging graphs from many small chunks can become computationally expensive and introduce noise. It's harder to establish strong, consistent relationships when each node and edge is derived from a tiny, isolated piece of text. This can dilute the significance of key information.\n\n2.  **Difficulty in Graph Merging and Consolidation:** When chunks are small and fragmented, the extracted subgraphs will be highly granular. Merging these can lead to:\n    *   **Redundant or Conflicting Information:** Similar facts or relationships might be extracted from slightly overlapping or adjacent chunks, making it challenging for the merging process to identify and consolidate them effectively. This exacerbates the \"repetitive information retrieval\" critique already observed.\n    *   **Loss of Global Context:** The overall narrative flow and thematic connections are likely to be obscured. The system might struggle to understand how events or entities across different small chunks relate to the broader story, leading to a shallow understanding.\n\n3.  **Impact on LLM Extraction Capabilities:**\n    *   **Limited Context for Graph Extraction:** The LLM tasked with extracting graphs from each chunk has a very limited window of text. This can lead to incomplete entity recognition, missed relationships, or misinterpretations, as it lacks the broader context to fully understand the significance of the information within that small chunk.\n    *   **Increased Ambiguity:** Small chunks can increase ambiguity. For example, a pronoun in one chunk might refer to a character introduced in a previous, now-discarded chunk, leading to extraction errors.\n\n**Recommendation for Improvement:**\n\nThe chunk size should be increased significantly. A larger chunk size (e.g., 200-500 tokens, depending on empirical testing) would allow for:\n\n*   ",
  "graph_builder_agent_critique": "Here's a critique of the graph construction prompt and resulting graph, focusing on improvements for a GraphRAG system:\n\n**Critique of Graph Construction Prompt & Resulting Graph:**\n\n1.  **Overly Generic Entity/Relationship Extraction:**\n    *   **Issue:** The prompt requests \"entities\" and \"relationships\" but lacks specific instructions for *what kind* of entities and relationships are most valuable for a RAG system. This leads to the observed abundance of generic relationship types like \"associated with\" (appears multiple times with different counts) and broad entity types like \"Concept\" and \"Object.\"\n    *   **Impact:** These generic labels create noise and reduce the precision of graph exploration. The LLM agent has to sift through many irrelevant or vague connections to find meaningful information. For instance, \"associated with\" doesn't tell the agent *how* entities are associated (e.g., is it a cause, an effect, a possession, a collaboration?).\n    *   **Suggestion:** The prompt should guide the LLM to identify *semantically rich* entities and relationships relevant to narrative or factual extraction. For relationships, it should encourage more specific types like \"causes,\" \"enables,\" \"located in,\" \"protagonist of,\" \"conflict with,\" \"developed by,\" \"discovered during,\" etc. For entities, it should encourage sub-typing where appropriate (e.g., distinguishing between a \"scientific concept\" and a \"narrative theme\").\n\n2.  **Lack of Explicit Role/Function Specification:**\n    *   **Issue:** The prompt asks for entity properties but doesn't emphasize identifying the *role* or *function* of entities within the text.\n    *   **Impact:** Knowing a person is a \"character\" is less useful than knowing they are the \"protagonist,\" \"antagonist,\" or \"mentor.\" Similarly, knowing an \"Object\" is a \"weapon\" is better than just \"object.\"\n    *   **Suggestion:** Add explicit instructions to identify and capture the functional role or significance of entities. For example: \"For each entity, also identify its role or function within the context of the text (e.g., protagonist, antagonist, McGuffin, scientific theory, historical event).\"\n\n3.  **Inconsistent Aggregation/Counting:**\n    *   **Issue:** The graph description shows duplicated relationship types with different counts (e.g., \"associated with\" appears with counts 8 and 3). This indicates an issue",
  "retrieval_planner_agent_critique": "Here's a critique of the provided retrieval plans, focusing on improvements:\n\n**Critique:**\n\n1.  **Redundant Exploration of Gurn's Neighbors:** Iterations 2, 3, and 6 all seem to be executing `get_neighbors(node_name='Gurn')` or similar calls that effectively re-explore Gurn's immediate connections. This is highly inefficient. Once Gurn's direct relationships are retrieved (likely in iteration 2), subsequent steps should focus on *deeper exploration* of *newly discovered* entities or *specific types of relationships* that are relevant to Gurn's role, rather than re-querying the same node. The system needs a mechanism to track already explored nodes and avoid repeating identical information retrieval.\n\n2.  **Lack of Strategic Depth and Synthesis:** The plan progresses from finding Gurn, to exploring its neighbors, then to exploring 'Vasads' neighbors, and then back to Gurn's neighbors again. This \"back and forth\" without clear progression towards synthesizing an answer to \"What is Gurn's role?\" is a weakness. The plan should move from broad discovery to focused analysis. For instance, after identifying \"leader of Vasads,\" the system could explore the *properties* or *relationships* of \"Vasads\" that define leadership, or explore *other entities* that interact with Gurn in a leadership capacity.\n\n3.  **Limited Use of Diverse Functions:** The plan heavily relies on `get_neighbors`. While useful, other functions like `search_relations_by_type` (e.g., to find all \"leader of\" relationships) or `analyze_path` (to understand connections between Gurn and other key characters) are underutilized. The strategy should leverage the full toolkit to gather complementary information.\n\n**Suggestions for Improvement:**\n\n1.  **State Management and Novelty Prioritization:** Implement a system to track visited nodes and relationships. Subsequent planning steps should prioritize exploring *unvisited* neighbors or *specific, relevant relationships* of already visited nodes, rather than repeating `get_neighbors` on the same entity.\n\n2.  **Goal-Oriented Exploration:** After initial discovery, the plan should have a clearer strategy for building the answer. For example, if \"leader of Vasads\" is found, the next logical step might be to explore \"Vasads\" specifically (as attempted in Iteration 4), but the subsequent return to \"Gurn\"",
  "answer_generation_critique": "Here's a critique of the current prompt and suggestions for improvement, focusing on the feedback provided:\n\n**Critique of Current Prompt and Suggestions for Improvement:**\n\nThe current prompt is good at setting the stage for an AI assistant to answer questions from a knowledge graph, emphasizing role definition and synthesis. However, it can be improved to more directly address the issues identified in the feedback, particularly regarding redundancy, flow, clarity of relationships, and organization.\n\n**1. Redundancy and Flow:**\n\n*   **Issue:** The prompt doesn't explicitly guide the LLM to consolidate similar roles or ensure smooth transitions between related pieces of information. This leads to listing \"leader\" and \"chief\" separately and slightly disjointed descriptions of affiliations.\n*   **Suggestion for Prompt Improvement:** Add an instruction that encourages consolidation and better integration of related concepts.\n    *   **Revised Prompt Instruction:** \"1. **Consolidate and Integrate:** Combine closely related terms or descriptions (e.g., 'leader' and 'chief') into a more concise and cohesive statement. Ensure that affiliations and descriptions are woven together logically rather than listed sequentially.\"\n\n**2. Clarity of Relationships and Past Events:**\n\n*   **Issue:** The prompt asks to \"Clarify Ambiguities,\" but it doesn't specifically address how to handle potentially complex or intertwined relationships, or how to present historical events clearly within the narrative of the role. The current prompt is too general here.\n*   **Suggestion for Prompt Improvement:** Add specific guidance on how to present relationships and past actions in a clear, unambiguous manner.\n    *   **Revised Prompt Instruction:** \"3. **Clarify Complexities and Sequence:** Clearly articulate relationships (e.g., family ties, alliances) and past events that define the subject's role. If a relationship or event is described in a way that might seem contradictory or complex in the source (e.g., 'Sarna is his father's woman'), present it directly as found but ensure the connection to the subject's role is explicit.\"\n\n**3. Organization by Category:**\n\n*   **Issue:** The prompt requests a logical structure (\"Organize your answer logically, starting with the most crucial aspects...\") but doesn't provide explicit categories or a framework for grouping information. This leaves the LLM to infer the best organizational strategy, leading to the scattered presentation observed.\n*   **Suggestion for Prompt Improvement:** Suggest a general organizational structure that helps group information thematically.\n    *   ",
  "graph_builder_prompt": "\nYou will be given a text. Your goal is to identify entities in the text and all the relationships among the identified entities.\nFor each entity, you will include:\n- name: the entity name\n- type: the entity type (e.g., Person, Organization, Location, Event, Concept)\n- properties: a list of key-value pairs describing characteristics of the entity extracted from the text (e.g., for a person: age, role, description; for a location: description, significance). Each property should have a \"key\" and \"value\" field.\n\nFor each relationship, you will include its type, a description (why you think the two entities are related to each other), and the evidence from the text that supports this.\nThe relationships must be among the extracted entities.\nProvide a list of triplets in your answer.\n\nReturn no more than 20 entities and 30 relationships. \n\nText:\n{TEXT_CHUNK}\n\nProvide the reasoning that led to your response.\n",
  "retrieval_prompt": "\nYour goal is to decide the next step of a strategy to explore a graph in order to retrieve relevant information to answer the following query: What is Gurn's role in the story?.\n\nA high-level description of the graph is the following: This graph contains 581 nodes and 979 relationships. The graph density is 0.0058, indicating a sparsely connected network. The graph is fully connected with a fragmentation index of 0.0000. The most frequent entity types are 201 \"\"s, 120 \"Location\"s, 63 \"Person\"s, 41 \"Concept\"s, 31 \"Object\"s, 20 \"Clothing\"s, 17 \"Weapon\"s, 16 \"Group\"s, 12 \"Artifact\"s, 8 \"Body Part\"s, 8 \"Event\"s, 8 \"Organization\"s, 6 \"Food & Drink\"s, 4 \"Animal\"s, and 3 \"ARTIFACT\"s. The most frequent relationship types are 19 \"attacks\" relationships, 17 \"located in\" relationships, 17 \"possesses\" relationships, 17 \"wears\" relationships, 16 \"observes\" relationships, 15 \"approaches\" relationships, 10 \"contains\" relationships, 9 \"associated with\" relationships, 8 \"associated with\" relationships, 8 \"inhabits\" relationships, 8 \"interacts with\" relationships, 7 \"is a\" relationships, 7 \"is in\" relationships, 7 \"speaks to\" relationships, and 7 \"wields\" relationships.\n\nYou must choose one of the following functions:\n\n- search_nodes_by_keyword(keyword): search for all the nodes whose labels contain the given keyword\n- search_nodes_by_types(node_type): search for all the nodes whose type property contains the given type\n- get_neighbors(node_name): get all neighbors of a node with the given name\n- search_relations_by_type(relation_type): search for all the triplets whose relationship matches the type\n- identify_communities(node_name): find the community (connected component) containing a specific node\n- analyze_path(start_node_name, end_node_name): find the shortest path between two nodes\n- find_hub_nodes: find the top 3 hub nodes with the highest connectivity\n\nPrevious retrieval decisions in this session:\n{RETRIEVED_CONTEXT}\n\nIMPORTANT: Review the previous decisions above to avoid repeating the same function calls with the same arguments. Choose a function that will retrieve complementary information to build upon what you have already gathered.\n\nChoose one of the functions and specify the arguments.\n\nProvide the reasoning that led to your response.\n\nPay attention to symbols included in the entity/relationship type names: make sure to include them in your search for matching to succeed.\nAlso, pay attention to symbols included in the functions names. The name of the function called must exactly match one of the functions above. \n"
}