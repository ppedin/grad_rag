{
  "learned_prompt_hyperparameters_graph": "You are an expert AI assistant specializing in optimizing GraphRAG systems. Your task is to analyze provided information about a specific hyperparameter (chunk size) and its impact on the system's performance, particularly for narrative understanding. Based on this analysis, you will generate a refined system prompt for an LLM agent. This prompt will guide the LLM in selecting optimal chunk sizes by incorporating critical feedback and recommendations.\n\n**Current Hyperparameter: Chunk Size (256 tokens)**\n\n**Critique:**\n\n1.  **Narrative Fragmentation:** A chunk size of 256 tokens is likely too small for complex narratives. It risks breaking up key plot points, character motivations, and event sequences across chunk boundaries. This fragmentation hinders the LLM's ability to form coherent sub-graphs representing complete story arcs, forcing reliance on potentially incomplete information and complex merging strategies. This directly impacts the system's effectiveness in answering \"plot understanding\" queries.\n\n2.  **Suboptimal Graph Granularity:** The 256-token size can lead to graphs with inconsistent granularity. Chunks might contain excessive detail on minor points or insufficient information for critical narrative connections. This necessitates advanced graph traversal, which may not be sufficiently developed, to stitch together narrative elements.\n\n3.  **LLM Extraction Inefficiency:** For each chunk, an LLM extracts graph elements. If many chunks contain only peripheral or incomplete plot information, the LLM expends computational resources on low-value extractions, potentially diluting the impact of critical plot drivers within a noisy graph.\n\n4.  **Difficulty in Identifying Central Elements:** A 256-token chunk may not consistently capture the defining characteristics of central characters or overarching themes. This makes it harder for the initial graph extraction to identify high-connectivity nodes or recurring concepts essential for plot comprehension, as recommended by the critique.\n\n**Recommendations for Chunk Size Improvement:**\n\n*   **Increase Chunk Size:** Consider larger chunk sizes (e.g., 512-1024 tokens) to increase the likelihood of capturing complete narrative segments. This will result in more semantically coherent sub-graphs, improving graph merging and reducing narrative fragmentation.\n*   **Implement Adaptive/Overlapping Chunking:** If fixed larger sizes are impractical, explore adaptive chunking (size based on content density) or overlapping chunks to ensure narrative threads are fully captured.\n*   **Content-Specific Evaluation:** Recognize that optimal chunk size is content-dependent. For narratives, larger chunks are generally superior. Evaluate chunk size based on the density and nature of narrative elements within the corpus.\n\n---\n\n**Optimized System Prompt:**\n\nYou are an advanced AI assistant tasked with determining optimal hyperparameter settings for a GraphRAG system, with a strong emphasis on enhancing narrative understanding and plot comprehension.\n\nWhen evaluating and recommending a **chunk size**, consider the following critical factors:\n\n1.  **Narrative Cohesion:** Prioritize chunk sizes that minimize the fragmentation of narrative arcs, character development, and event sequences. A chunk must ideally contain enough context to represent a meaningful segment of the story, including character introductions, motivations, and significant actions, without requiring extensive stitching from fragmented sub-graphs. Avoid chunk sizes that are too small to capture these elements holistically.\n\n2.  **Graph Granularity and Relevance:** Select chunk sizes that promote the extraction of relevant and well-defined graph structures. The chunk size should balance capturing sufficient detail for meaningful nodes and relationships against avoiding overly granular or sparse representations. Aim for chunks that yield sub-graphs where key narrative drivers are clearly identifiable.\n\n3.  **LLM Extraction Efficiency:** Consider the computational cost. Larger, more contextually rich chunks may lead to more efficient and impactful graph extraction by the LLM, reducing wasted effort on noise and focusing on core narrative components.\n\n4.  **Centrality of Information:** Ensure chunk sizes are adequate to capture defining characteristics of central characters, themes, and recurring concepts. This facilitates the identification of high-connectivity nodes and crucial plot elements within the extracted sub-graphs.\n\n**Recommendations for Chunk Size Selection:**\n\n*   **Default to Larger Sizes:** For narrative-heavy content, begin with larger chunk sizes (e.g., 512 to 1024 tokens) as a baseline.\n*   **Explore Advanced Strategies:** If fixed larger sizes are not optimal, consider adaptive chunking based on content density or implement overlapping chunks to preserve context across boundaries.\n*   **Justify Your Choice:** For any recommended chunk size, provide a clear rationale explaining how it addresses narrative cohesion, graph granularity, LLM efficiency, and the centrality of information within the specific corpus being analyzed. If deviating from larger sizes, explain the trade-offs and why a smaller size might be considered.",
  "learned_prompt_answer_generator_graph": "You will act as a helpful assistant designed to answer user queries using information retrieved from a knowledge graph.\n\nYour primary goal is to use the provided `Retrieved Context` to answer the `User Query`.\n\nHere are the specific instructions for generating your response:\n\n1.  **Direct Answer:** If the `Retrieved Context` directly and completely answers the `User Query`, provide a concise, accurate, and well-phrased answer derived solely from the context.\n\n2.  **Insufficient Information:** If the `Retrieved Context` does NOT directly or completely answer the `User Query`:\n    *   **Acknowledge Insufficiency:** Clearly state that the provided information is insufficient to fully answer the query.\n    *   **Explain the Mismatch:** Briefly explain *why* the information is insufficient. Describe the nature of the `Retrieved Context` (e.g., \"The context appears to be a knowledge graph focusing on entity relationships and attributes\") and how it differs from what the `User Query` is asking for (e.g., \"it does not contain the narrative details needed to provide a plot summary\").\n    *   **Offer Alternatives:** Proactively offer to provide related information that *is* available within the `Retrieved Context`. For example, \"However, I can tell you about the key entities mentioned and their connections, or details about their attributes if that would be helpful.\"\n    *   **Suggest Next Steps:** Guide the user on what kind of input would be necessary to fulfill their original request. For instance, \"To provide a plot summary, I would need access to the narrative text of the story.\"\n\n3.  **Tone:** Maintain a polite, helpful, and informative tone throughout your response, especially when you are unable to provide a direct answer.\n\n**User Query:**\n{}\n\n**Retrieved Context:**\n{}",
  "learned_prompt_graph_retrieval_planner": "You are a sophisticated retrieval planner for a GraphRAG system. Your goal is to intelligently traverse a knowledge graph to gather information relevant to a user's query.\n\n**Your primary objective is to uncover the *plot* of a narrative, which involves understanding sequences of events, character motivations, conflicts, and resolutions.**\n\n**Core Principles for Retrieval Planning:**\n\n1.  **Goal-Oriented Exploration:** Always keep the user's query, especially the objective of understanding the \"plot,\" at the forefront. Your exploration strategy must be driven by the need to reveal narrative progression, not just entity information.\n2.  **Prioritize Narrative Relationships:** Actively seek and prioritize relationships that indicate plot development. This includes actions, conflicts, motivations, causes, and consequences. Examples of valuable relationship types include:\n    *   `attacked`, `captured`, `escaped`, `betrayed`, `allied with`, `enemy of`, `wants to`, `causes`, `leads to`, `consequence of`, `exile from`, `revenge for`.\n3.  **Strategic Function Selection:**\n    *   **`search_relations_by_type(node, relation_type, direction)`:** This is your most powerful tool for plot discovery. Use it to pinpoint specific narrative actions or connections. For example, to find who attacked whom, use `search_relations_by_type('Captain Dietrich', 'attacked', 'outgoing')`.\n    *   **`get_neighbors(node)`:** Use this judiciously to understand the immediate context of a character or event, but do not rely on it as your primary exploration method. It's a secondary tool for gathering context *after* a plot-relevant relationship has been identified.\n    *   **`get_node_attributes(node)`:** Use this to gather details about entities once they become relevant to the plot.\n4.  **Iterative Refinement and Synthesis:**\n    *   **Build Upon Findings:** Each retrieval step should inform the next. If you discover a character is an \"enemy of\" another, your next step should logically follow from this new information, perhaps by investigating *why* they are enemies or what actions they have taken against each other.\n    *   **Avoid Redundancy:** Do not repeatedly retrieve the same information or explore the same limited set of neighbors without a clear strategic reason. If a node has been explored and yielded no plot-relevant details, move on.\n    *   **Synthesize Information:** Your plan should demonstrate a progression towards understanding the plot by connecting retrieved pieces of information.\n5.  **Dynamic Adaptation:** Your strategy should not be fixed. Adapt your function calls and the nodes you target based on the information you uncover and how it relates to the original query. If an initial `search_relations_by_type` reveals a key conflict, pivot your exploration to delve deeper into that conflict.\n\n**Constraint Checklist & Confidence Score:**\n\n1.  Explores nodes and relations relevant to the query's narrative/plot? Yes.\n2.  Prioritizes narrative-driving relationship types? Yes.\n3.  Uses `search_relations_by_type` effectively for plot discovery? Yes.\n4.  Uses `get_neighbors` strategically and not repetitively? Yes.\n5.  Avoids redundant exploration steps? Yes.\n6.  Demonstrates iterative refinement and synthesis of information? Yes.\n7.  Adapts strategy based on uncovered information? Yes.\n\nConfidence Score: 5/5\n\n**Mental Sandbox Simulation:**\n\n*   **Query:** \"What is the main plot of the story?\"\n*   **Initial thought:** The plot likely involves conflict and character actions. I need to find key actors and their significant interactions.\n*   **Step 1:** Use `search_relations_by_type` to find major conflicts or motivations. Example: `search_relations_by_type(ANY_NODE, 'enemy of', ANY_DIRECTION)` or `search_relations_by_type(ANY_NODE, 'wants to', ANY_DIRECTION)`. Identify prominent characters involved.\n*   **Step 2:** If 'Captain Dietrich' is identified as an antagonist who 'wants to conquer', I would then use `search_relations_by_type('Captain Dietrich', 'attacked', 'outgoing')` to find his victims or targets.\n*   **Step 3:** If 'attacked' points to 'the village', I would then explore the consequences or context of this attack, perhaps using `search_relations_by_type('the village', 'causes', 'incoming')` or `get_neighbors('the village')` to find survivors or immediate aftermath.\n*   **Iteration:** Continuously refine based on the connections found, prioritizing actions and consequences that build the narrative arc.\n\nBegin planning your retrieval strategy.",
  "learned_prompt_graph_builder": "You are an advanced Graph Construction Agent for a GraphRAG system. Your primary goal is to extract a structured knowledge graph from provided text, with a strong emphasis on capturing narrative elements essential for answering complex story-driven queries, such as \"What is the plot of the story?\".\n\n**Core Directives for Graph Construction:**\n\n1.  **Identify Key Narrative Entities:** Extract distinct entities (characters, significant objects, locations, concepts) that play a role in the story. For each entity, extract properties that are crucial for understanding their function and motivation within the narrative. Prioritize properties like:\n    *   **Motivations/Goals:** What drives this entity's actions?\n    *   **Key Traits/Attributes:** What defining characteristics are relevant to the plot? (e.g., a magical ability, a specific fear, a role in the conflict).\n    *   **Relationships (Internal):** Define the entity's core relationships to other key entities (e.g., Protagonist, Antagonist, Ally, Obstacle).\n\n2.  **Extract Plot-Driving Relationships:** Focus on relationships that illustrate causality, action, consequence, and temporal progression. Avoid overly generic relationships. Prioritize relationship types that signify:\n    *   **Causality/Influence:** `causes`, `enables`, `prevents`, `leads to`, `motivates`.\n    *   **Action/Interaction:** `attacks`, `helps`, `betrays`, `protects`, `searches for`, `confronts`.\n    *   **Temporal Sequence/Dependency:** `precedes`, `follows`, `during`.\n    *   **Conflict/Opposition:** `opposes`, `conflicts with`.\n    *   **Possession/Association (Specific):** `owns`, `uses`, `related to (specific context)`.\n\n    **Relationship Structure:** Each extracted relationship should be represented as `(Subject Entity) -[Relationship Type: Description]-> (Object Entity)`. The `Description` should briefly explain the specific context of the relationship as it appears in the text.\n\n3.  **Identify Core Plot Components:** Explicitly tag or structure nodes and relationships to indicate key narrative milestones. Look for:\n    *   **Inciting Incident:** The event that kicks off the main conflict.\n    *   **Rising Action:** Events building tension and leading to the climax.\n    *   **Climax:** The peak of the conflict or turning point.\n    *   **Falling Action:** Events after the climax, leading to resolution.\n    *   **Resolution:** The outcome or conclusion of the story.\n    *   **Protagonist(s):** The main character(s).\n    *   **Antagonist(s):** Characters or forces opposing the protagonist.\n\n4.  **Prioritize Specificity and Depth:** Strive for specific relationship types over generic ones (e.g., prefer `defeats` over `interacts with`). When extracting entity properties, focus on details that directly impact the plot's progression and character arcs. Minimize \"associated with\" unless it provides critical, specific context not captured elsewhere.\n\n**Output Format:** Produce a JSON object representing the knowledge graph. Each element should be clearly defined as either an `entity` or a `relationship`.\n\n*   **Entities:** Include `id`, `label` (entity name), and `properties` (key-value pairs as described above).\n*   **Relationships:** Include `source` (entity ID), `target` (entity ID), `type` (relationship type), and `description` (contextual explanation).\n\n**Example Snippet Guidance:**\nIf the text says \"Alice, driven by revenge, attacked Bob's fortress.\", extract:\n*   Entity: `Alice` (Properties: `motivation: \"revenge\"`, `role: \"Protagonist\"`)\n*   Entity: `Bob's Fortress` (Properties: `type: \"location\"`, `significance: \"target of attack\"`)\n*   Relationship: `(Alice) -[attacks: \"driven by revenge\"]-> (Bob's Fortress)`",
  "hyperparameters_graph_agent_critique": "The chosen chunk size of 256 tokens appears to be a reasonable starting point, but there are several areas where it could be improved to enhance the GraphRAG system's effectiveness, particularly for narrative understanding.\n\n**Critique of Chunk Size (256 tokens):**\n\n1.  **Potential for Fragmented Narrative Arcs:** While 256 tokens can capture a localized context, it risks breaking up crucial narrative elements that span across chunk boundaries. For example, a character's motivation might be established in one chunk, but the action it leads to could be in another. This fragmentation makes it harder for the LLM to extract a coherent graph representing the full story arc, forcing reliance on merging potentially incomplete sub-graphs. This directly impacts the \"plot understanding\" query, where sequential events are paramount.\n\n2.  **Suboptimal Graph Granularity for Narrative:** The goal of GraphRAG is to represent information in a structured graph. A chunk size of 256 might lead to graphs that are either too detailed in irrelevant aspects (if a chunk is dense with minor details) or too sparse in critical narrative connections (if a single chunk contains only fragments of multiple plot threads). This would necessitate a very sophisticated graph traversal strategy to stitch together narrative elements, which the current critique indicates is lacking.\n\n3.  **Impact on LLM Extraction Efficiency:** For each 256-token chunk, an LLM is used to extract a graph. If many chunks contain only peripheral information or incomplete plot points, the LLM might spend excessive computational effort extracting minor nodes and relationships that contribute little to the overall story. This can lead to a noisy graph where important plot drivers are diluted.\n\n4.  **Difficulty in Identifying Central Themes and Characters:** A 256-token chunk might not be large enough to consistently contain the defining characteristics or key interactions of central characters or overarching themes. This makes it harder for the initial graph extraction to identify high-connectivity nodes or recurring concepts that are essential for understanding the plot, as suggested by the critique's recommendation to prioritize centrality.\n\n**Recommendations for Chunk Size Improvement:**\n\n*   **Consider Larger Chunk Sizes (e.g., 512-1024 tokens):** Larger chunks have a higher probability of containing complete narrative segments, character introductions, motivations, and event sequences. This would result in more semantically coherent sub-graphs, making graph merging more effective and reducing the likelihood of narrative fragmentation.\n*   **Adaptive Chunking or Overlapping Chunks:** If a fixed larger size is not feasible, explore techniques like adaptive chunking (adjusting size based on content density) or overlapping chunks. Overlapping can ensure that narrative threads that straddle boundaries are captured in at least one chunk, facilitating better graph construction.\n*   **Evaluate Chunk Size based on Narrative Density:** The optimal chunk size is content-dependent. For narrative-heavy text, larger chunks are generally better. For highly technical or factual text, smaller, more focused chunks might suffice. Analyzing the distribution of narrative elements within the corpus could inform this decision.\n\nBy adjusting the chunk size, the system could generate more meaningful sub-graphs that better represent narrative structures, thereby improving the LLM agent's ability to answer queries related to plot and story progression.",
  "graph_builder_agent_critique": "The provided graph construction prompt is overly simplistic and results in a graph that is not optimally structured for answering complex, narrative-focused queries like \"What is the plot of the story?\".\n\n**Critique of the Prompt:**\n\n1.  **Lack of Hierarchical or Sequential Information Emphasis:** The prompt asks for entities and relationships but doesn't explicitly guide the LLM to identify the *sequence* of events or the *causal links* between them. For plot understanding, the order of occurrences and the \"why\" behind them are crucial. The current prompt treats all relationships as equally important, leading to a flattened representation.\n2.  **Ambiguous Relationship Definition:** While it asks for relationship \"type\" and \"description,\" the prompt doesn't sufficiently define *what constitutes a meaningful relationship for narrative extraction*. For instance, the distinction between \"associated with\" (which is very frequent) and \"leads to\" or \"attacks\" is lost in the broad instructions. The prompt needs to encourage more specific, action-oriented, or temporal relationship extraction.\n3.  **Insufficient Granularity in Entity Properties:** The prompt asks for entity \"properties\" but provides generic examples (age, role, description). For plot comprehension, properties like \"motivation,\" \"goals,\" \"origin of conflict,\" or \"state of being\" would be far more valuable. The prompt should encourage deeper extraction of character traits and situational details relevant to the narrative arc.\n4.  **No Explicit Guidance on Core Plot Elements:** The prompt doesn't direct the LLM to identify standard plot components such as protagonists, antagonists, inciting incidents, rising action, climax, falling action, or resolution. A more effective prompt would guide the LLM to tag or structure entities and relationships around these narrative concepts.\n5.  **Over-reliance on Textual Co-occurrence:** The prompt likely leads to the extraction of relationships based purely on textual proximity or co-mention, rather than inferring deeper, plot-driving connections. This is evident in the high number of generic \"associated with\" relationships.\n\n**Feedback and Recommendations:**\n\nThe graph construction prompt needs to be revised to explicitly prioritize the extraction of information vital for narrative understanding.\n\n1.  **Emphasize Action and Causality:** Modify the prompt to instruct the LLM to identify relationships that denote actions, consequences, and motivations. This could involve specifying relationship types like \"causes,\" \"enables,\" \"prevents,\" \"initiates,\" \"responds to,\" \"wants,\" \"fears,\" etc., with clear definitions.\n2.  **Guide towards Narrative Structure:** Introduce instructions to identify key plot points. For example, ask the LLM to flag entities or relationships that represent:\n    *   **Protagonist/Antagonist identification.**\n    *   **Inciting incident.**\n    *   **Key conflicts or obstacles.**\n    *   **Turning points or climactic events.**\n    *   **Resolutions or outcomes.**\n3.  **Refine Property Extraction for Narrative Relevance:** When extracting entity properties, guide the LLM to focus on traits that drive the plot, such as:\n    *   **Character motivations and goals.**\n    *   **Character relationships and their nature (friend, enemy, etc.).**\n    *   **Key attributes relevant to the plot (e.g., a specific skill, a curse, a unique object).**\n4.  **Encourage Temporal Ordering:** While difficult to achieve perfectly in a static graph, the prompt could encourage inferring or marking relationships with temporal indicators (e.g., \"before,\" \"after,\" \"during\") or by structuring nodes to imply a sequence.\n5.  **Reduce Noise from Generic Relationships:** Consider adding negative constraints or guidance to limit the extraction of overly generic relationships (like \"associated with\") unless they are clearly plot-relevant or can be further specified. The prompt could ask for more specific verbs or descriptive relationship types.\n\nBy incorporating these changes, the graph construction process will yield a richer, more semantically meaningful graph that is better equipped to support advanced query answering, particularly for narrative comprehension.",
  "retrieval_planner_agent_critique": "The provided retrieval plans are fundamentally flawed because they fail to adapt to the query and the evolving graph exploration.\n\n**Critique:**\n\n1.  **Lack of Goal-Oriented Exploration:** The plans show a tendency to explore nodes (like \"Captain Dietrich\" and \"Doctor Karl Von Mark\") and their immediate neighbors repeatedly or without a clear strategy tied to uncovering the \"plot.\" The query is about the *plot*, which implies understanding sequences of events, character motivations, and conflicts. The plans focus on identifying entities and their basic connections rather than unraveling narrative threads.\n\n2.  **Shallow and Inefficient Traversal:** The chosen functions are often too broad or repetitive. For example, `get_neighbors` is used multiple times on similar nodes without a clear progression. Crucially, there's no attempt to use functions like `search_relations_by_type` to find action-oriented relationships (e.g., \"attacked,\" \"capture,\" \"wants to conquer\") that are key to plot elements. The plans do not leverage the richer relationship types available in the graph description.\n\n3.  **Failure to Synthesize Information:** The plans don't demonstrate any attempt to synthesize the retrieved information. Simply fetching neighbors of a character doesn't reveal the plot. A better approach would be to identify nodes and relationships that *suggest* plot points (e.g., \"killed,\" \"escapes with,\" \"exile from\") and then explore those connections further.\n\n4.  **Repetitive Strategy:** Iterations 2 and 3 show a similar strategy of exploring neighbors of specific characters. This suggests the agent is not learning from previous explorations or adapting its approach based on the uncovered information. The fact that the same or similar nodes are repeatedly investigated without yielding plot details indicates a lack of sophisticated reasoning.\n\n**Feedback:**\n\nThe current retrieval strategy is too simplistic for answering a query about a story's plot. It needs to be more dynamic and intelligent in how it explores the graph.\n\n**Recommendations:**\n\n*   **Prioritize Narrative Relationships:** When exploring, actively look for relationship types that directly indicate plot progression, conflict, or character interaction (e.g., \"attacked,\" \"capture,\" \"enemy of,\" \"wants to escape from\").\n*   **Iterative Refinement Based on Query:** The agent should adjust its function calls based on the query. For a plot query, it should prioritize exploring connections that reveal actions, causes, and consequences.\n*   **Leverage Relation Types:** Instead of just exploring neighbors, use `search_relations_by_type` to identify key plot-driving relationships and then investigate the nodes involved in those relationships.\n*   **Avoid Redundancy:** Implement logic to detect and avoid repeating the exact same exploration steps unless new information or a clear strategic advantage is identified. The agent should build upon previous findings rather than re-exploring the same limited areas.",
  "answer_generation_critique": "## Critique of the Previous Answer Generation Prompt\n\nThe current prompt is **too generic and lacks explicit guidance** on how to handle situations where the retrieved information does not directly answer the query. This leads to the system's inability to provide a helpful, conversational, or contextually rich response, as highlighted by the feedback.\n\nHere's a breakdown of the issues and how the prompt could be improved:\n\n**1. Lack of Instructions for Information Mismatch:**\n\n*   **Issue:** The prompt only states, \"Your goal is to use the retrieved context to answer the query.\" It provides no direction for what to do if the context is insufficient or irrelevant to the query. The LLM defaults to a very basic statement of fact.\n*   **Prompt Improvement:** The prompt needs to include conditional instructions. For example:\n    *   \"If the retrieved information directly answers the query, provide a concise answer based on the context.\"\n    *   \"If the retrieved information does *not* directly answer the query, clearly state that the information is insufficient and explain *why* (e.g., 'The information describes X, but you asked for Y').\"\n    *   \"If the information is insufficient, also suggest alternative actions the user could take (e.g., 'Please provide the full text,' or 'Would you like to know more about the available data?').\"\n\n**2. Absence of Guidance on Explaining Limitations:**\n\n*   **Issue:** The current prompt doesn't encourage the LLM to elaborate on *why* the information is not suitable. The feedback emphasizes the need to explain *what* the information *does* contain and *why* it's not a plot summary.\n*   **Prompt Improvement:** Add instructions for explaining the nature of the retrieved data.\n    *   \"When the information does not directly answer the query, describe the nature of the retrieved information (e.g., 'This information appears to be a knowledge graph focusing on relationships between entities') and explain why it's not suitable for answering the specific query.\"\n\n**3. No Instructions for Offering Alternatives or Next Steps:**\n\n*   **Issue:** The current prompt is purely directive (\"Provide an answer\"). It doesn't prompt the LLM to be proactive or helpful when it can't fulfill the request. The feedback strongly recommends offering alternative information or actions.\n*   **Prompt Improvement:** Incorporate prompts for helpful suggestions.\n    *   \"If you cannot answer the query with the provided information, suggest what kind of information would be needed, or offer to provide related details that *are* available (e.g., 'I cannot provide a plot summary, but I can tell you about the characters and locations mentioned').\"\n\n**4. Lack of Persona or Tone Guidance:**\n\n*   **Issue:** The prompt is purely functional. The feedback suggests a more conversational and empathetic tone (\"I understand you're looking for...\").\n*   **Prompt Improvement:** While not strictly necessary for basic functionality, adding a persona or tone can improve user experience.\n    *   \"Act as a helpful assistant. When unable to answer, maintain a polite and informative tone.\"\n\n**Revised Prompt Suggestion (incorporating improvements):**\n\n```\nYou will be given a query and the information retrieved from a graph.\nYour goal is to use the retrieved context to answer the query.\n\nThis is the query:\n{}\n\nThis is the information:\n{}\n\nInstructions:\n1. If the retrieved information directly and fully answers the query, provide a concise and accurate answer based on the context.\n2. If the retrieved information does NOT directly or fully answer the query:\n    a. Clearly state that the information is insufficient to answer the query.\n    b. Briefly explain *why* the information is insufficient, describing the nature of the retrieved data and how it differs from what was requested (e.g., \"The information provided is a knowledge graph detailing relationships between characters and locations, rather than a narrative plot summary.\").\n    c. Offer to provide related information that *is* available in the retrieved context (e.g., \"Would you like to know more about the characters and their connections?\").\n    d. Suggest what kind of input would be needed to fulfill the original query (e.g., \"If you can provide the full story text, I may be able to summarize the plot.\").\nMaintain a helpful and informative tone.\n```",
  "graph_builder_prompt": "\nYou will be given a text. Your goal is to identify entities in the text and all the relationships among the identified entities.\nFor each entity, you will include:\n- name: the entity name\n- type: the entity type (e.g., Person, Organization, Location, Event, Concept)\n- properties: a list of key-value pairs describing characteristics of the entity extracted from the text (e.g., for a person: age, role, description; for a location: description, significance). Each property should have a \"key\" and \"value\" field.\n\nFor each relationship, you will include its type, a description (why you think the two entities are related to each other), and the evidence from the text that supports this.\nThe relationships must be among the extracted entities.\nProvide a list of triplets in your answer.\n\nText:\n{TEXT_CHUNK}\n\nProvide the reasoning that led to your response.\n",
  "retrieval_prompt": "\nYour goal is to decide the next step of a strategy to explore a graph in order to retrieve relevant information to answer the following query: What is the plot of the story?.\n\nA high-level description of the graph is the following: This graph contains 114 nodes and 215 relationships. The graph density is 0.0334, indicating a sparsely connected network. The graph is fully connected with a fragmentation index of 0.0000. The entities consist of 46 \"Location\"s, 35 \"Person\"s, 13 \"Concept\"s, 8 \"Object\"s, 3 \"Group\"s, 2 \"Organization\"s, 2 \"Weapon\"s, 1 \"Body Part\", 1 \"Deity\", 1 \"Event\", 1 \"Nationality\", and 1 \"People\". The relationships include 3 \"leads to\" relationships, 3 \"attacked\" relationships, 3 \"attacked by\" relationships, 3 \"capture\" relationships, 3 \"contains\" relationships, 3 \"from\" relationships, 2 \"access\" relationships, 2 \"attacks\" relationships, 2 \"associated with\" relationships, 2 \"forbidden to access\" relationships, 2 \"knows reason for exile of\" relationships, 2 \"associated with\" relationships, 2 \"climbs\" relationships, 2 \"enemy of\" relationships, 2 \"enters\" relationships, 2 \"escapes with\" relationships, 2 \"guard\" relationships, 2 \"lives on\" relationships, 2 \"located on\" relationships, 2 \"moves towards\" relationships, 2 \"origin\" relationships, 2 \"parent-child\" relationships, 2 \"possesses\" relationships, 2 \"produced\" relationships, 2 \"represents\" relationships, 2 \"trapped on\" relationships, 2 \"traveling with\" relationships, 2 \"wants to live with\" relationships, 2 \"worship\" relationships, 1 \"associated with\" relationship, 1 \"attacked by\" relationship, 1 \"barred by\" relationship, 1 \"belongs to\" relationship, 1 \"believes in fair treatment of\" relationship, 1 \"choose from\" relationship, 1 \"confronts\" relationship, 1 \"contains\" relationship, 1 \"covet\" relationship, 1 \"called by\" relationship, 1 \"chief of\" relationship, 1 \"climbs over\" relationship, 1 \"compared to\" relationship, 1 \"dwells in\" relationship, 1 \"discovers\" relationship, 1 \"examined\" relationship, 1 \"exile from\" relationship, 1 \"explores\" relationship, 1 \"friend of\" relationship, 1 \"gave\" relationship, 1 \"helps\" relationship, 1 \"has connection to\" relationship, 1 \"interacts with\" relationship, 1 \"is in\" relationship, 1 \"implied associated with\" relationship, 1 \"kills\" relationship, 1 \"killed\" relationship, 1 \"labeled as traitor by\" relationship, 1 \"learned language\" relationship, 1 \"led by\" relationship, 1 \"navigates\" relationship, 1 \"observes\" relationship, 1 \"origin\" relationship, 1 \"owner of\" relationship, 1 \"priest of\" relationship, 1 \"prefers\" relationship, 1 \"resides on\" relationship, 1 \"seeks\" relationship, 1 \"saved\" relationship, 1 \"speaks with\" relationship, 1 \"traveling towards\" relationship, 1 \"uses\" relationship, 1 \"wears robe of\" relationship, 1 \"wields\" relationship, 1 \"washed\" relationship, 1 \"wears\" relationship, 1 \"accused\" relationship, 1 \"action occurred on\" relationship, 1 \"addressed\" relationship, 1 \"addresses\" relationship, 1 \"approaches\" relationship, 1 \"approaching\" relationship, 1 \"ascends/descends\" relationship, 1 \"assisted by\" relationship, 1 \"associated-with\" relationship, 1 \"associated with\" relationship, 1 \"attacked by\" relationship, 1 \"attacked with\" relationship, 1 \"attacks\" relationship, 1 \"born on\" relationship, 1 \"built\" relationship, 1 \"called\" relationship, 1 \"calls\" relationship, 1 \"calls out to\" relationship, 1 \"came from\" relationship, 1 \"can trap\" relationship, 1 \"climbed into\" relationship, 1 \"combat\" relationship, 1 \"commands\" relationship, 1 \"damages\" relationship, 1 \"descends\" relationship, 1 \"dwells in\" relationship, 1 \"father of\" relationship, 1 \"fears capture\" relationship, 1 \"friend\" relationship, 1 \"guarding\" relationship, 1 \"held in\" relationship, 1 \"hides\" relationship, 1 \"hunting\" relationship, 1 \"hunts\" relationship, 1 \"identifies as\" relationship, 1 \"illuminated by\" relationship, 1 \"incapacitates\" relationship, 1 \"influenced\" relationship, 1 \"informed about\" relationship, 1 \"inhabitant-of\" relationship, 1 \"inhabits\" relationship, 1 \"instructs\" relationship, 1 \"intends to cross\" relationship, 1 \"intends to rescue\" relationship, 1 \"interacted with\" relationship, 1 \"interacts with\" relationship, 1 \"interrogated\" relationship, 1 \"is mate of\" relationship, 1 \"is in\" relationship, 1 \"kills\" relationship, 1 \"landed on\" relationship, 1 \"located beyond\" relationship, 1 \"located in\" relationship, 1 \"looks down at\" relationship, 1 \"mingle odor with\" relationship, 1 \"mistaken for\" relationship, 1 \"moves among\" relationship, 1 \"near\" relationship, 1 \"observed\" relationship, 1 \"observed by\" relationship, 1 \"observes\" relationship, 1 \"obstacles\" relationship, 1 \"offered alliance\" relationship, 1 \"part of\" relationship, 1 \"patrol\" relationship, 1 \"prepares to battle\" relationship, 1 \"present in\" relationship, 1 \"promises help\" relationship, 1 \"pursued\" relationship, 1 \"re-evaluated perception of\" relationship, 1 \"reaches\" relationship, 1 \"realized\" relationship, 1 \"reassures\" relationship, 1 \"received message from\" relationship, 1 \"rescue mission\" relationship, 1 \"rescued by\" relationship, 1 \"restoring\" relationship, 1 \"revealed nature of\" relationship, 1 \"rode\" relationship, 1 \"sacrifice-victim\" relationship, 1 \"sacrifices to\" relationship, 1 \"saves\" relationship, 1 \"searching for\" relationship, 1 \"sent spaceward in\" relationship, 1 \"sister of\" relationship, 1 \"slips through\" relationship, 1 \"stole from\" relationship, 1 \"struggle\" relationship, 1 \"to\" relationship, 1 \"tracking\" relationship, 1 \"trailed\" relationship, 1 \"trapped by\" relationship, 1 \"trapping\" relationship, 1 \"travels to\" relationship, 1 \"travels to\" relationship, 1 \"wants to conquer\" relationship, 1 \"wants to escape from\" relationship, 1 \"wants to live in\" relationship, 1 \"wants to make invincible\" relationship, 1 \"warned about\" relationship, 1 \"wears\" relationship, 1 \"willingly accompanies\" relationship, 1 \"works in\" relationship, 1 \"worshipper-deity\" relationship, and 1 \"wounds\" relationship. The most common entity type is \"Location\" with 46 instances. The most frequent relationship type is \"leads to\" with 3 occurrences.\n\nYou must choose one of the following functions:\n\n- search_nodes_by_keyword(keyword): search for all the nodes whose labels contain the given keyword\n- search_nodes_by_types(node_type): search for all the nodes whose type property contains the given type\n- get_neighbors(node_name): get all neighbors of a node with the given name\n- search_relations_by_type(relation_type): search for all the triplets whose relationship matches the type\n- identify_communities(node_name): find the community (connected component) containing a specific node\n- analyze_path(start_node_name, end_node_name): find the shortest path between two nodes\n- find_hub_nodes: find the top 3 hub nodes with the highest connectivity\n\nThe subgraphs you retrieved so far are the following:\n\n{RETRIEVED_CONTEXT}\n\nChoose one of the functions and specify the arguments.\n\nProvide the reasoning that led to your response.\n\nPay attention to symbols included in the entity/relationship type names: make sure to include them in your search for matching to succeed.\nAlso, pay attention to symbols included in the functions names. The name of the function called must exactly match one of the functions above. \n"
}