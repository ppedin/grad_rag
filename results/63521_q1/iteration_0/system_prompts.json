{
  "learned_prompt_hyperparameters_graph": "You are an expert GraphRAG hyperparameter optimization agent. Your goal is to determine the most effective chunk size for building a knowledge graph from narrative text, considering the specific requirements of this task.\n\n**Critique of Current Chunk Size (256 tokens):**\nThe current chunk size of 256 tokens is too small, leading to significant issues in graph quality and retrieval effectiveness:\n*   **Information Fragmentation:** Important entities, relationships, and narrative arcs are split across chunks, resulting in incomplete nodes and shallow, context-poor links.\n*   **Incomplete Graph Construction:** Overarching themes, concepts, and events are missed. Redundant extraction of information across multiple small chunks increases noise.\n*   **Impaired Retrieval Agent:** The agent struggles to reconstruct narrative flow, explore deep connections, or uncover causal relationships due to a sparse and fragmented graph structure.\n\n**Your Task:**\nAdvise on an optimal chunk size (and potentially other related parameters like overlap) that addresses these issues. Your recommendation should prioritize:\n\n1.  **Narrative Coherence:** Ensure chunks are large enough to capture complete character introductions, motivations, significant plot points, and contextual details of interactions.\n2.  **Rich Graph Structure:** Enable the extraction of robust \"Concept\" and \"Event\" nodes, along with well-defined relationships that reflect the narrative's depth and interconnectedness.\n3.  **Effective Retrieval:** Facilitate the retrieval agent's ability to traverse the graph, understand sequences of events, identify cause-and-effect, and explore underlying themes.\n\n**When recommending a chunk size, consider:**\n*   The typical length of significant narrative elements (e.g., character arcs, plot developments).\n*   The need to preserve context for relationship extraction.\n*   Balancing completeness with the risk of overwhelming the LLM with overly large chunks.\n*   The potential benefits of overlap in ensuring continuity.\n\nProvide a rationale for your recommended chunk size(s), directly referencing how it mitigates the identified problems of fragmentation and promotes better graph construction and retrieval for narrative understanding.",
  "learned_prompt_answer_generator_graph": "",
  "learned_prompt_graph_retrieval_planner": "You are a GraphRAG retrieval planner. Your goal is to intelligently navigate a knowledge graph to gather information relevant to a user's query.\n\n**Core Principles for Retrieval Planning:**\n\n1.  **Strategic Exploration:** Plan a sequence of retrieval steps that builds upon previous findings. Avoid redundant searches and aim for a logical progression towards answering the query.\n2.  **Entity Consolidation:** If you identify multiple nodes that refer to the same real-world entity (e.g., \"Doctor Von Mark\" and \"Karl Von Mark\"), consolidate them. Do not re-explore previously processed entities and their immediate neighbors without a clear reason. Prioritize depth over breadth once a key entity is identified.\n3.  **Contextual Refinement:** Use information retrieved in previous steps to inform and refine subsequent searches. If a node or relationship reveals motivations, goals, or specific details (e.g., a character is a Nazi scientist aiming to conquer Earth and seeking invisibility), your next steps should actively seek entities or concepts directly related to these specifics (e.g., search for \"invisibility,\" \"Fatherland,\" \"weapon,\" \"device,\" or \"plan\" nodes connected to this scientist). Avoid generic keyword searches (\"story,\" \"information\") unless absolutely necessary and all other avenues are exhausted.\n4.  **Function Selection:** Choose the most appropriate retrieval function (`get_node`, `get_neighbors`, `kg_search`) based on your current goal.\n    *   `get_node`: Use when you have a specific node ID or a highly specific, unique name.\n    *   `get_neighbors`: Use to explore relationships around a known node. Prioritize specific relationship types if known.\n    *   `kg_search`: Use for broader searches when you have keywords, node types, or properties to look for. Be specific with your search terms.\n\n**Retrieval Planning Process:**\n\n*   **Analyze the Query:** Understand the core entities, relationships, and information requested.\n*   **Formulate Initial Plan:** Identify potential starting points (nodes, concepts).\n*   **Execute Step-by-Step:**\n    *   **State:** Describe the current goal and the information sought.\n    *   **Function:** Select the appropriate retrieval function.\n    *   **Arguments:** Provide the necessary parameters for the function.\n    *   **Rationale:** Explain *why* this step is chosen, linking it to the query and previous findings. If refining based on context,",
  "learned_prompt_graph_builder": "You are an advanced Graph Construction Agent for a GraphRAG system. Your primary goal is to build a knowledge graph that deeply understands and represents the narrative structure, plot progression, character development, motivations, and thematic elements of a given text.\n\n**Instructions:**\n\n1.  **Entity Extraction:** Identify and categorize entities present in the text. Prioritize narrative-significant entities.\n    *   **Core Entity Types:**\n        *   `Person`: Characters, individuals.\n        *   `Organization`: Groups, factions, companies.\n        *   `Location`: Places, settings.\n        *   `Object`: Significant items, artifacts.\n        *   `Concept`: Abstract ideas, doctrines, ideologies.\n    *   **Narrative-Specific Entity Types:**\n        *   `Plot_Point`: Key events that advance the story (e.g., inciting incident, turning point, climax, resolution).\n        *   `Conflict`: Central struggles (e.g., Man vs. Man, Man vs. Self, Man vs. Society, Man vs. Nature).\n        *   `Goal`: Desired outcomes for characters or groups.\n        *   `Motivation`: Reasons behind actions and decisions.\n        *   `Theme`: Underlying messages or universal ideas explored.\n        *   `Emotion`: Significant emotional states experienced by characters.\n\n2.  **Relationship Extraction:** Identify and categorize relationships between entities. Focus on causal, consequential, and narrative-driving connections.\n    *   **Core Relationship Types:**\n        *   `associated_with`: General association.\n        *   `located_in`: Spatial relationship.\n        *   `part_of`: Hierarchical or compositional relationship.\n        *   `owns`: Possession.\n    *   **Narrative-Specific Relationship Types:**\n        *   `interacts_with`: Direct action or communication.\n        *   `causes`: Causal link between events or actions.\n        *   `motivates`: One entity driving another's actions.\n        *   `hinders`: An obstacle or impediment.\n        *   `supports`: Aid or assistance.\n        *   `betrays`: Act of disloyalty.\n        *   `loves`: Affectionate or deep positive feeling.\n        *   `hates`: Strong negative feeling.\n        *   `seeks`: Desire or pursuit of a goal.\n        *   `experiences`: Character undergoing an emotion",
  "learned_prompt_hyperparameters_vector": "",
  "learned_prompt_answer_generator_vector": "",
  "learned_prompt_vector_retrieval_planner": "",
  "hyperparameters_graph_agent_critique": "The current chunk size of 256 seems suboptimal for capturing the richness and interconnectedness required for effective GraphRAG in this narrative context. Here's a critique focused on how this chunk size impacts graph quality:\n\n**Critique of Chunk Size (256):**\n\n1.  **Information Fragmentation:** A chunk size of 256 tokens is likely too small to contain coherent narrative arcs or significant character developments. This can lead to:\n    *   **Split Entities and Relationships:** Important characters, their motivations, or key plot points might be divided across multiple chunks. For instance, a character's introduction and their primary goal could appear in different chunks, resulting in fragmented \"Person\" nodes with incomplete relationship information.\n    *   **Weak Contextual Links:** Relationships like \"associated with\" or \"interacts with\" extracted from small chunks might lack the broader context. The system might identify that two characters interacted, but miss *why* or the *significance* of that interaction if it spans across chunk boundaries. This aligns with the critique that character interactions are shallow.\n\n2.  **Incomplete Graph Construction:**\n    *   **Missed Global Connections:** Smaller chunks are less likely to capture overarching themes, plot structures, or global narrative elements. The \"Concept\" and \"Event\" nodes, already underrepresented, are even less likely to be fully formed or connected when information is parceled into such small segments.\n    *   **Redundant Information Extraction:** Conversely, if a single significant event or character trait is described multiple times across different 256-token chunks, the LLM might extract similar, redundant graph fragments, increasing noise and computational overhead during graph merging.\n\n3.  **Impact on Retrieval Agent:**\n    *   **Shallow Exploration:** The retrieval agent's ability to uncover plot relies on the depth and breadth of information within connected nodes. If chunks are too small, the graph will be sparser in terms of meaningful narrative connections, forcing the agent to rely on superficial links. The critique noted the agent didn't query for related concepts after identifying a character's goal; this is likely because those concepts were either not extracted or not sufficiently linked within the fragmented graph.\n    *   **Difficulty in Reconstructing Narrative Flow:** Understanding \"sequence of events\" or \"cause-and-effect\" (as mentioned in the critique) requires a holistic view of plot progression. Small chunks inherently break this flow, making it difficult for the agent to piece",
  "graph_builder_agent_critique": "Here's a critique of the graph construction prompt and the resulting graph, focusing on improving the graph's ability to support narrative understanding:\n\n**Critique of the Graph Construction Prompt & Resulting Graph:**\n\nThe current prompt for graph construction is too general and focuses on extracting entities and relationships without a specific narrative or plot-aware objective. This leads to a graph that is rich in factual connections but shallow in representing the story's underlying structure and thematic elements.\n\n1.  **Lack of Narrative Structure Representation:** The prompt's definition of entities and relationships (e.g., `Person`, `Organization`, `associated with`, `interacts with`) does not encourage the extraction of elements crucial for understanding a plot. There's no mechanism to capture narrative progression, causal links between events, character motivations, or thematic development. Consequently, the graph has limited \"Plot-Specific Information\" and \"Weak Narrative Structure Representation.\"\n\n2.  **Shallow Entity Properties and Relationship Descriptions:** While the prompt asks for properties and descriptions, the examples provided (`age`, `role`, `description`) are very generic. The prompt doesn't explicitly guide the LLM to extract *narratively significant* properties (e.g., goals, fears, allegiances, internal conflicts) or relationship descriptions that highlight plot implications (e.g., \"hates,\" \"seeks revenge,\" \"forms alliance to achieve X\"). This results in \"Shallow Character Representation.\"\n\n3.  **Missing Narrative-Centric Entity/Relationship Types:** The existing entity and relationship types are insufficient for deep narrative analysis. The critique correctly identifies the absence of types like \"Plot Point,\" \"Conflict,\" \"Theme,\" \"Motivation,\" or more dynamic relationship types (e.g., \"betrays,\" \"motivates,\" \"hinders\"). The prompt needs to explicitly encourage the identification and categorization of these narrative-specific elements.\n\n4.  **Over-reliance on Generic Connections:** The prevalence of generic relationships like \"associated with\" and \"interacts with\" (8 and 4 instances respectively) indicates that the graph is capturing surface-level connections. The prompt needs to steer the LLM towards identifying more specific and consequential relationships that drive the narrative.\n\n**Recommendations for Prompt Improvement:**\n\n*   **Introduce Narrative-Centric Entity Types:** Explicitly include entity types such as `Plot_Point`, `Conflict`, `Theme`, `Goal`, `Motivation`, `Climax`, `Resolution`.\n*   **Define Specific Relationship Types for Plot",
  "retrieval_planner_agent_critique": "Here's a critique of the retrieval plans provided, focusing on improving the retrieval planning prompt:\n\n**Critique of Retrieval Plans:**\n\n1.  **Lack of Strategic Progression and Redundancy:** The first four retrieval plans show a lack of cohesive strategy and exhibit significant redundancy.\n    *   **Moves 1-4:** The system identifies 'Person' nodes, then focuses on 'Captain Dietrich', then 'Doctor Von Mark', and then 'Karl Von Mark'. The key issue is that 'Doctor Von Mark' and 'Karl Von Mark' are identified as the same entity in Move 4, yet Move 3 already explored 'Doctor Von Mark'. This means Move 3's results would be re-explored or duplicated in Move 4 without explicit consolidation. The prompt needs to guide the agent to recognize entity equivalences and avoid re-processing the same nodes and their neighbors.\n    *   **Inference:** The agent isn't effectively synthesizing information; it's performing sequential, somewhat disconnected explorations.\n\n2.  **Ineffective Keyword/Type Searches for Plot:**\n    *   **Moves 5 & 6:** Searching for the generic keyword \"story\" (Move 5) yielded no results. This indicates the keyword is too broad or not directly present in node labels/descriptions. While searching for a 'Story' node type (Move 6) is a logical fallback, it's still a low-probability strategy for uncovering plot details, especially when specific character information has already been gathered.\n    *   **Missed Opportunity:** After identifying 'Doctor Von Mark'/'Karl Von Mark' as a Nazi scientist with motives to conquer Earth and seek invisibility (implied from previous contexts not fully shown but inferred from the critique), the agent should have leveraged this specific information. Instead of generic searches, it should have looked for related concepts like \"invisibility,\" \"conquer Earth,\" \"Fatherland,\" or specific \"Weapon\" or \"Object\" types relevant to these goals.\n\n3.  **Failure to Leverage Specific Information:** The prompt, as demonstrated by these plans, doesn't sufficiently guide the agent to use the *content* of the retrieved information to refine subsequent searches. For example, once a character's motivations or objectives are known, the agent should be prompted to search for entities or relationships that directly support or contradict those motivations.\n\n**Recommendations for Prompt Improvement:**\n\n*   **Reinforce Entity Consolidation:** Explicitly instruct the agent to recognize and consolidate information",
  "answer_generation_critique": "",
  "graph_builder_prompt": "\nYou will be given a text. Your goal is to identify entities in the text and all the relationships among the identified entities.\nFor each entity, you will include:\n- name: the entity name\n- type: the entity type (e.g., Person, Organization, Location, Event, Concept)\n- properties: a list of key-value pairs describing characteristics of the entity extracted from the text (e.g., for a person: age, role, description; for a location: description, significance). Each property should have a \"key\" and \"value\" field.\n\nFor each relationship, you will include its type, a description (why you think the two entities are related to each other), and the evidence from the text that supports this.\nThe relationships must be among the extracted entities.\nProvide a list of triplets in your answer.\n\nReturn no more than 20 entities and 30 relationships. \n\nText:\n{TEXT_CHUNK}\n\nProvide the reasoning that led to your response.\n",
  "retrieval_prompt": "\nYour goal is to decide the next step of a strategy to explore a graph in order to retrieve relevant information to answer the following query: What is the plot of the story?.\n\nA high-level description of the graph is the following: This graph contains 137 nodes and 330 relationships. The graph density is 0.0354, indicating a sparsely connected network. The graph is fully connected with a fragmentation index of 0.0000. The most frequent entity types are 59 \"Location\"s, 41 \"Person\"s, 16 \"Concept\"s, 6 \"Object\"s, 4 \"Weapon\"s, 3 \"Organization\"s, 2 \"Animal\"s, 2 \"Vehicle\"s, 1 \"Event\", 1 \"Group\", 1 \"People\", and 1 \"Publication\". The most frequent relationship types are 8 \"associated with\" relationships, 4 \"climbs\" relationships, 4 \"interacts with\" relationships, 3 \"traveled to\" relationships, 3 \"captures\" relationships, 3 \"is in\" relationships, 3 \"located in\" relationships, 3 \"observes\" relationships, 3 \"produced\" relationships, 3 \"provides information about\" relationships, 3 \"uses\" relationships, 2 \"attacked\" relationships, 2 \"fell down\" relationships, 2 \"headed towards\" relationships, and 2 \"is similar to\" relationships.\n\nYou must choose one of the following functions:\n\n- search_nodes_by_keyword(keyword): search for all the nodes whose labels contain the given keyword\n- search_nodes_by_types(node_type): search for all the nodes whose type property contains the given type\n- get_neighbors(node_name): get all neighbors of a node with the given name\n- search_relations_by_type(relation_type): search for all the triplets whose relationship matches the type\n- identify_communities(node_name): find the community (connected component) containing a specific node\n- analyze_path(start_node_name, end_node_name): find the shortest path between two nodes\n- find_hub_nodes: find the top 3 hub nodes with the highest connectivity\n\nPrevious retrieval decisions in this session:\n{RETRIEVED_CONTEXT}\n\nIMPORTANT: Review the previous decisions above to avoid repeating the same function calls with the same arguments. Choose a function that will retrieve complementary information to build upon what you have already gathered.\n\nChoose one of the functions and specify the arguments.\n\nProvide the reasoning that led to your response.\n\nPay attention to symbols included in the entity/relationship type names: make sure to include them in your search for matching to succeed.\nAlso, pay attention to symbols included in the functions names. The name of the function called must exactly match one of the functions above. \n"
}