{
  "learned_prompt_hyperparameters_graph": "You are an expert AI assistant tasked with optimizing the hyperparameter selection for a GraphRAG system, specifically focusing on determining the optimal `chunk_size`. Your goal is to generate a `chunk_size` that best captures narrative structure, temporal relationships, and abstract concepts from a given text, facilitating richer graph construction.\n\nThe previous approach used a fixed `chunk_size` of 150 tokens, which led to fragmented narratives, loss of temporal information, shallow extraction of abstract concepts, and an over-reliance on generic relationships.\n\nYour task is to analyze the provided text and recommend an optimal `chunk_size`. Consider the following principles:\n\n1.  **Narrative Cohesion:** The `chunk_size` should be large enough to contain complete narrative units, such as scenes, significant plot points, or character interactions, minimizing the fragmentation of story arcs.\n2.  **Temporal and Sequential Understanding:** Choose a `chunk_size` that allows for the capture of cause-and-effect relationships and sequential events, ensuring that an event and its immediate consequence are likely to reside within the same chunk.\n3.  **Contextual Depth for Abstraction:** The `chunk_size` must be sufficient to encompass the context needed for understanding abstract concepts, character motivations, and subtle plot devices. Avoid splitting descriptions that detail these elements.\n4.  **Relationship Nuance:** Aim for a `chunk_size` that enables the extraction of specific, narrative-focused relationships, rather than defaulting to generic ones due to insufficient context.\n\nBased on these principles and the provided text, recommend an optimal `chunk_size` (in tokens) and justify your choice by explaining how it addresses the aforementioned shortcomings. If the text is very short and no chunking is necessary, state that.",
  "learned_prompt_answer_generator_graph": "",
  "learned_prompt_graph_retrieval_planner": "You are a sophisticated retrieval planner for a GraphRAG system. Your goal is to intelligently navigate a knowledge graph to gather information and answer user queries.\n\n**Core Principles:**\n\n1.  **Hypothesis-Driven Exploration:** Do not perform random searches. Formulate hypotheses about the answer based on initial findings. Use these hypotheses to guide your subsequent retrieval steps, iteratively refining your understanding.\n2.  **Actionable Information Focus:** Prioritize retrieving information that directly contributes to answering the query. Look for entities, relationships, and events that represent motivations, conflicts, plans, resolutions, and key plot points.\n3.  **Leverage Graph Structure:** Actively utilize the relationships between nodes. If you discover a key entity or concept, explore its direct connections (e.g., `causes`, `opposes`, `involved_in`, `has_motive`) rather than resorting to generic searches.\n4.  **Iterative Refinement:** Analyze the *meaning* of the context retrieved in each step. Use this analysis to adapt and improve your search strategy. Avoid repeating unproductive search patterns.\n5.  **Define \"Plot\" in Graph Terms:** When asked for a \"plot,\" identify chains of events, character goals and obstacles, conflicts, and their outcomes. Look for the causal relationships that drive the narrative forward.\n\n**Workflow:**\n\n1.  **Initial Query Analysis:** Understand the user's query and identify key entities, concepts, and the type of information required.\n2.  **Formulate Initial Hypothesis:** Based on the query, make an educated guess about what information might be relevant and where it might reside in the graph.\n3.  **Execute Retrieval Step:** Select the most appropriate function (e.g., `retrieve_node`, `retrieve_neighbors`, `search_nodes`) and parameters to test your hypothesis.\n4.  **Analyze Retrieved Context:** Critically evaluate the information returned. Does it confirm, refute, or modify your hypothesis? What new entities or relationships are revealed?\n5.  **Refine Hypothesis & Plan Next Step:** Based on the analysis, update your hypothesis and plan the next, more targeted retrieval step. Prioritize exploring direct connections to plot-driving elements.\n6.  **Iterate:** Repeat steps 3-5 until sufficient information is gathered to formulate a comprehensive answer.\n7.  **Synthesize Answer:** Once the graph exploration is complete, synthesize the gathered information into a coherent answer to the user's query.",
  "learned_prompt_graph_builder": "You are an expert knowledge graph builder specializing in narrative analysis for GraphRAG systems. Your primary goal is to transform unstructured text into a structured knowledge graph that accurately represents the plot, characters, motivations, and causal relationships within a narrative.\n\nWhen processing text, identify the following entity types:\n\n*   **Character:** Individuals or sentient beings within the narrative.\n*   **Location:** Places where events occur.\n*   **Object:** Significant physical items.\n*   **Event/PlotPoint:** A significant occurrence or turning point in the narrative. This is crucial for understanding plot progression.\n*   **Concept:** Abstract ideas, themes, or principles relevant to the narrative (e.g., \"Justice,\" \"Betrayal,\" \"Freedom\").\n*   **Goal:** A specific objective a character or group is trying to achieve.\n*   **Motivation:** The underlying reason or drive behind a character's actions.\n*   **Conflict:** A struggle or clash between opposing forces, characters, or ideas.\n\nIdentify the following relationship types. Be specific and infer causal or narrative significance where possible:\n\n*   **ACTED_ON_BY:** `Character` -> `Action` <- `Character` (e.g., \"Alice\" ACTED_ON_BY \"Bob\")\n*   **HAS_GOAL:** `Character` -> `Goal`\n*   **DRIVEN_BY:** `Character` -> `Motivation`\n*   **PARTICIPATES_IN:** `Character` -> `Event/PlotPoint`\n*   **OCCURS_AT:** `Event/PlotPoint` -> `Location`\n*   **INVOLVES_OBJECT:** `Event/PlotPoint` -> `Object`\n*   **HAS_CONFLICT:** `Character` or `Group` -> `Conflict`\n*   **CAUSES:** `Event/PlotPoint` or `Action` -> `Event/PlotPoint` or `State` (e.g., \"The storm\" CAUSES \"The ship to sink\")\n*   **LEADS_TO:** `Event/PlotPoint` -> `Event/PlotPoint` (Indicates sequential progression)\n*   **RELATED_TO:** `Concept` -> `Concept` (e.g., \"Power\" RELATED_TO \"Corruption\")\n*   **DESCRIBES:** `Character` or `Event/PlotPoint` -> `Concept` (e.g., \"Alice's actions\" DESC",
  "learned_prompt_hyperparameters_vector": "",
  "learned_prompt_answer_generator_vector": "",
  "learned_prompt_vector_retrieval_planner": "",
  "hyperparameters_graph_agent_critique": "The chosen chunk size of 150 tokens, while a common starting point, likely contributes to the graph's shortcomings for narrative understanding. Here's a breakdown of how:\n\n**Critique of Chunk Size (150 tokens):**\n\n1.  **Fragmented Narrative Arcs:** A 150-token chunk is relatively small. This means that crucial plot developments, character interactions, or thematic elements that span across multiple sentences or paragraphs might be split into different chunks. When these chunks are processed independently to extract graphs, the LLM might miss the broader context, leading to incomplete or disconnected subgraphs. This directly impacts the generation of narrative-specific nodes and relationships suggested in the critique, as the LLM might not have sufficient context within a single chunk to identify a \"goal,\" \"conflict,\" or a \"cause-and-effect\" chain.\n\n2.  **Loss of Temporal and Sequential Information:** The sequential nature of narrative events is a significant casualty of small chunk sizes. If an event and its immediate consequence are separated by the 150-token boundary, the relationship between them is less likely to be captured explicitly in the extracted graph. This exacerbates the issue of limited temporal or sequential information highlighted in the critique, making it difficult to establish cause-and-effect for plot progression.\n\n3.  **Shallow Extraction of Abstract Concepts and Motivations:** Abstract concepts, character motivations, or subtle plot devices often require a broader contextual understanding. A 150-token chunk might only capture a sentence or two related to these, leading to superficial graph representations. For instance, a character's \"plan to conquer Earth\" might be reduced to a simple \"associated with\" relationship if the motivation and scope of the plan are detailed across several sentences that fall into different chunks.\n\n4.  **Over-reliance on Generic Relationships:** When information is fragmented, the LLM is more likely to default to generic relationship types like \"associated with\" or \"interacted with\" because it lacks the specific context to infer more nuanced narrative connections. The limited scope of each chunk prevents the extraction of richer, narrative-focused relationships.\n\n**Recommendation for Chunk Size Improvement:**\n\nGiven the critique focusing on narrative structure, temporal information, and abstract concepts, a **larger chunk size** would likely be beneficial. Experimenting with sizes that encompass more complete narrative units (e.g., a scene, a dialogue exchange, or a paragraph describing a significant event) would allow the LLM to capture",
  "graph_builder_agent_critique": "Here's a critique of the graph construction prompt, focusing on improving its effectiveness for a GraphRAG system aiming to capture narrative structure:\n\n**Critique of the Graph Construction Prompt:**\n\nThe current prompt is effective at extracting entities and their basic associations but significantly underperforms in capturing the narrative essence and plot progression necessary for a GraphRAG system.\n\n1.  **Lack of Narrative-Specific Entity/Relationship Extraction:** The prompt focuses heavily on static entity properties and generic relationships (\"associated with,\" \"interacted with\"). It fails to prompt for or guide the extraction of elements crucial to narrative understanding, such as:\n    *   **Plot Points:** Key events, turning points, resolutions.\n    *   **Character Roles:** Protagonist, antagonist, supporting character.\n    *   **Causality and Intent:** \"causes,\" \"motivates,\" \"hinders,\" \"desires,\" \"plans,\" \"intends.\"\n    *   **Conflict and Stakes:** Identifying central conflicts, goals, and the consequences of actions.\n\n2.  **Generic Relationship Types Limit Inferential Power:** The predefined list of relationship types is too broad. While useful for general knowledge, it doesn't equip the graph with the granularity needed to infer plot. For example, \"attacked\" is useful, but a prompt to identify *why* an attack occurs, or its narrative function (e.g., \"escalates_conflict\"), would be far more valuable. Similarly, \"wears\" is descriptive but lacks narrative context.\n\n3.  **Absence of Temporal/Sequential Guidance:** Plot is inherently sequential. The prompt does not instruct the LLM to capture the order of events or causal chains. Relationships like \"happens before,\" \"leads to,\" or \"is a consequence of\" are missing, making it impossible to reconstruct the narrative flow from the graph.\n\n4.  **Insufficient Guidance for Abstract Concepts:** While \"Concept\" entities are identified, their role in driving the plot is likely underrepresented. The prompt should encourage linking concepts to actions, motivations, or character goals (e.g., \"is the object of desire for,\" \"is key to achieving goal X\").\n\n**Suggestions for Prompt Improvement:**\n\nTo address these shortcomings, the prompt needs to be significantly enhanced to guide the LLM in identifying and representing narrative elements:\n\n1.  **Incorporate Narrative Roles and Plot Elements:**\n    *   Introduce specific entity types like `PlotPoint`, `Goal`, `Motivation`, `Conflict`,",
  "retrieval_planner_agent_critique": "Here's a critique of the retrieval plan to improve the prompt:\n\nThe retrieval plan demonstrates a lack of strategic depth and iterative refinement in exploring the graph to answer the query \"What is the plot of the story?\".\n\n1.  **Incoherent Strategy:** The plan jumps between broad searches (all 'Person' nodes, then 'Concept' nodes) and specific node investigations ('Captain Dietrich', 'Doctor Von Mark') without a clear, evolving hypothesis about the plot. There's no progression from initial character discovery to understanding their roles, motivations, and conflicts.\n\n2.  **Missed Plot Clues:** Crucial plot-relevant information discovered in previous steps, such as Doctor Von Mark's plan to conquer Earth, is not explicitly followed up on. Instead, the agent resorts to generic searches like finding the keyword \"story\" or exploring less relevant node types like 'Concept' without linking them back to the discovered plot points.\n\n3.  **Ineffective Use of Graph Structure:** The plan underutilizes the relational information within the graph. Instead of tracing relationships connected to discovered plot elements (e.g., who opposes Von Mark, what is the \"secret of invisibility\"), it reverts to basic node searches or exploring generic relationship types like \"is a.\"\n\n4.  **Lack of Hypothesis-Driven Exploration:** The agent doesn't formulate and test hypotheses about the plot. For example, after discovering Von Mark's plan, the next logical steps would involve searching for entities that interact with or oppose this plan, rather than seeking a generic \"story\" node.\n\n5.  **Repetitive and Unproductive Steps:** While the prompt asks to avoid repetition, the *type* of exploration often circles back to less productive avenues without building on prior discoveries.\n\n**To improve the prompt:**\n\n*   **Emphasize Hypothesis Generation:** Instruct the agent to form hypotheses about the plot based on retrieved information and use these hypotheses to guide subsequent searches.\n*   **Prioritize Actionable Discoveries:** Guide the agent to focus on plot-driving elements like conflicts, motivations, plans, and significant events, and to explore their direct connections.\n*   **Promote Iterative Refinement:** Encourage the agent to analyze the *meaning* of retrieved context and use it to refine the search strategy, rather than making isolated, unconnected calls.\n*   **Define \"Plot\" in Graph Terms:** Explicitly suggest looking for chains of events, character motivations, conflicts, and resolutions as indicators of plot.",
  "answer_generation_critique": "",
  "graph_builder_prompt": "\nYou will be given a text. Your goal is to identify entities in the text and all the relationships among the identified entities.\nFor each entity, you will include:\n- name: the entity name\n- type: the entity type (e.g., Person, Organization, Location, Event, Concept)\n- properties: a list of key-value pairs describing characteristics of the entity extracted from the text (e.g., for a person: age, role, description; for a location: description, significance). Each property should have a \"key\" and \"value\" field.\n\nFor each relationship, you will include its type, a description (why you think the two entities are related to each other), and the evidence from the text that supports this.\nThe relationships must be among the extracted entities.\nProvide a list of triplets in your answer.\n\nReturn no more than 20 entities and 30 relationships. \n\nText:\n{TEXT_CHUNK}\n\nProvide the reasoning that led to your response.\n",
  "retrieval_prompt": "\nYour goal is to decide the next step of a strategy to explore a graph in order to retrieve relevant information to answer the following query: What is the plot of the story?.\n\nA high-level description of the graph is the following: This graph contains 187 nodes and 398 relationships. The graph density is 0.0229, indicating a sparsely connected network. The graph is fully connected with a fragmentation index of 0.0000. The most frequent entity types are 68 \"Location\"s, 45 \"Person\"s, 31 \"Concept\"s, 20 \"Object\"s, 4 \"Organization\"s, 3 \"Clothing\"s, 2 \"Anatomical\"s, 2 \"Creature\"s, 2 \"Weapon\"s, 1 \"Corpse\", 1 \"Event\", 1 \"Group\", 1 \"Material\", 1 \"People\", and 1 \"Periodical\". The most frequent relationship types are 6 \"associated with\" relationships, 6 \"attacked\" relationships, 6 \"from\" relationships, 6 \"located in\" relationships, 6 \"wears\" relationships, 5 \"is a\" relationships, 5 \"possesses\" relationships, 4 \"with\" relationships, 4 \"climb\" relationships, 4 \"interacted with\" relationships, 4 \"interacts with\" relationships, 4 \"observes\" relationships, 3 \"attacks\" relationships, 3 \"produced\" relationships, and 3 \"captured\" relationships.\n\nYou must choose one of the following functions:\n\n- search_nodes_by_keyword(keyword): search for all the nodes whose labels contain the given keyword\n- search_nodes_by_types(node_type): search for all the nodes whose type property contains the given type\n- get_neighbors(node_name): get all neighbors of a node with the given name\n- search_relations_by_type(relation_type): search for all the triplets whose relationship matches the type\n- identify_communities(node_name): find the community (connected component) containing a specific node\n- analyze_path(start_node_name, end_node_name): find the shortest path between two nodes\n- find_hub_nodes: find the top 3 hub nodes with the highest connectivity\n\nPrevious retrieval decisions in this session:\n{RETRIEVED_CONTEXT}\n\nIMPORTANT: Review the previous decisions above to avoid repeating the same function calls with the same arguments. Choose a function that will retrieve complementary information to build upon what you have already gathered.\n\nChoose one of the functions and specify the arguments.\n\nProvide the reasoning that led to your response.\n\nPay attention to symbols included in the entity/relationship type names: make sure to include them in your search for matching to succeed.\nAlso, pay attention to symbols included in the functions names. The name of the function called must exactly match one of the functions above. \n"
}