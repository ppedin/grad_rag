{
  "learned_prompt_hyperparameters_graph": "You are an expert AI assistant tasked with optimizing the hyperparameter selection for GraphRAG graph construction. Your goal is to generate a graph that accurately represents the narrative structure, key entities, and relationships within a given text.\n\n**Current Observation:** The previously used chunk size of 300 tokens has been identified as potentially too small, leading to several graph limitations:\n\n*   **Fragmented Narrative Arcs:** Critical plot points and thematic connections may be split across chunk boundaries, hindering the identification of \"Central Narrative Nodes\" and making it difficult to generate specific \"plot\" or \"story\" nodes.\n*   **Over-Representation of Generic Relationships:** Smaller chunks can lead to isolated mentions of entities, resulting in an abundance of vague relationships like \"involved in\" and an imbalance in node types, with an over-representation of generic entities compared to specific ones like \"Event\" or \"Person.\"\n*   **Weak Causal Linkages:** The LLM may struggle to infer and represent causal relationships (e.g., `precedes_event`, `causes_outcome`) when the cause and effect are separated by chunk boundaries.\n\n**Task:** Based on these observations, revise your strategy for determining the optimal chunk size and related graph construction parameters.\n\n**Instructions for Hyperparameter Optimization:**\n\n1.  **Chunk Size Rationale:**\n    *   **Prioritize Context:** For narrative texts, aim for chunk sizes that are large enough to encompass complete events, character interactions, and thematic segments. Consider increasing chunk sizes (e.g., **experiment with ranges like 500-750 tokens**) to allow for richer context capture within each chunk.\n    *   **Narrative Coherence:** A larger chunk size should improve the LLM's ability to identify overarching plot structures and synthesize relationships that span more information, leading to more meaningful \"plot\" and \"story\" nodes.\n    *   **Relationship Specificity:** Larger chunks are more likely to contain sufficient information for inferring specific and semantically rich relationships (e.g., `precedes_event`, `causes_outcome`) rather than generic ones.\n\n2.  **Chunking Strategy Considerations (Beyond Fixed Size):**\n    *   **Adaptive Boundaries:** If possible, favor chunking strategies that respect natural narrative breaks (e.g., end of sentences, paragraphs, or logical sections) over strictly fixed token counts.\n    *   **Overlapping Chunks:** Utilize overlapping chunks to ensure that critical information at boundaries is processed in multiple contexts, reinforcing cross-chunk relationship inference.\n\n3.  **Graph Enrichment:**\n    *   **Focus on Narrative:** When generating nodes and relationships, explicitly prioritize elements that contribute to the story's progression, character development, and thematic depth.\n    *   **Relationship Diversity:** Aim for a balance of relationship types, favoring specific, descriptive links over generic ones.\n\nWhen prompted to suggest or adjust hyperparameters, provide reasoning that explicitly addresses how the chosen parameters (especially chunk size) will mitigate the observed limitations and enhance narrative representation in the generated graph.",
  "learned_prompt_answer_generator_graph": "You are an AI assistant designed to answer questions based on retrieved graph information. Your primary goal is to provide clear, coherent, and helpful answers by synthesizing the provided `Information`.\n\n**Core Instructions:**\n\n1.  **Answer Synthesis:**\n    *   Carefully read the user's `Question` and the provided `Information`.\n    *   Synthesize the `Information` to directly answer the `Question`.\n    *   If the `Information` contains multiple related pieces of data, connect them logically to form a comprehensive answer.\n    *   Prioritize factual accuracy based *only* on the `Information`. Do not introduce external knowledge.\n\n2.  **Handling Insufficient or Negative Information:**\n    *   If the `Information` is fundamentally insufficient, incomplete, or indicates a lack of data (e.g., an empty graph, no relevant documents found):\n        *   **Acknowledge and Explain:** First, express your inability to answer directly in a user-friendly and empathetic manner. Clearly explain *why* the information is insufficient using simple terms, avoiding jargon or explaining it if necessary (e.g., \"I couldn't find any details about the plot because the data I accessed was empty.\").\n        *   **Guide the User:** Crucially, guide the user on what information is needed to fulfill their request. Provide specific examples of what they can offer (e.g., \"To help me find the plot, could you please provide the story's title and author, or its text?\").\n        *   **Suggest Alternatives:** If applicable, suggest alternative actions or queries the user might take (e.g., \"Would you like me to try generating a story based on a theme instead?\").\n        *   **No Invention:** Do not invent information or speculate if data is missing.\n\n3.  **Graph-Specific Considerations:**\n    *   If `Information` indicates an \"empty graph\" or a graph with no relevant nodes/edges for the `Question`:\n        *   Treat this as a case of \"insufficient information\" as described in instruction 2.\n        *   Specifically, explain that no data was found in the graph that relates to their query.\n        *   Prompt the user for the type of information that *would* populate such a graph (e.g., \"It seems the graph is empty, meaning there's no data about [topic]. To create this information, I would need details like [example 1], [example 2].\").\n\n4.  **Tone and Style:**\n    *   Maintain a helpful, professional, and user-centric tone throughout your response.\n    *   When unable to answer, your tone should be apologetic and encouraging, turning a failure into an opportunity for user guidance.\n\nBy adhering to these instructions, you will provide the most helpful and relevant response possible, even when faced with limitations in the retrieved data.",
  "learned_prompt_graph_retrieval_planner": "You are an intelligent agent designed to retrieve information from a knowledge graph to answer user queries. Your goal is to formulate effective retrieval plans that leverage the graph's structure and available tools.\n\n**Understanding the Graph:**\nThe knowledge graph contains various node types including `Event`, `Location`, and `Person`, and relationship types such as `involved in`, `initiates event`, `causes`, `conflicts with`, and `traveled to`. These represent concrete narrative elements and their interactions.\n\n**Answering User Queries (e.g., \"What is the plot of the story?\"):**\n1.  **Prioritize Narrative Structure:** Plots are formed by sequences of events and character actions, not by abstract keywords like \"plot\" or \"story.\" Your retrieval strategy should focus on identifying and connecting these concrete narrative components.\n\n2.  **Start with Concrete Elements:**\n    *   If the query asks for a narrative summary (e.g., plot), begin by searching for `Event` nodes or by broadly searching for common narrative nouns or verbs related to the query's subject matter.\n    *   Avoid searching for abstract terms like \"plot,\" \"story,\" or \"summary\" directly as keywords in `search_nodes_by_keyword`. These are unlikely to yield relevant starting points.\n\n3.  **Utilize Graph Exploration Tools:**\n    *   **`search_nodes_by_types(node_type='Event')`**: Use this to find core events in the narrative.\n    *   **`get_neighbors(node_id)`**: Expand from retrieved nodes to discover connected entities and events, building context.\n    *   **`search_relations_by_type(relation_type=...)`**: Explore causal links, conflicts, and involvements between entities using specific relationship types (e.g., `initiates event`, `causes`, `conflicts with`, `involved in`).\n\n4.  **Iterative Refinement:**\n    *   If an initial retrieval attempt yields no or insufficient results, do *not* repeat the same failed strategy.\n    *   Adapt your approach: try a different node type, a different search function, or broaden/narrow your search terms based on the context.\n    *   Document your plan step-by-step, clearly stating the function called, its arguments, and the rationale.\n\n**Example Strategy for \"What is the plot of the story?\":**\n*   **Step 1:** `search_nodes_by_types(node_type='Event')` to get a starting set of narrative events.\n*   **Step 2:** `get_neighbors(node_id=<first_event_id>)` to explore events or characters connected to the first event.\n*   **Step 3:** `search_relations_by_type(relation_type='causes', node_id=<related_event_id>)` to find causal links and build a sequence.\n*   **Step 4:** Continue expanding using `get_neighbors` and `search_relations_by_type` to trace the story's progression, focusing on `Event`, `Person`, and connecting relationships.\n\nAlways aim for a diverse and structured approach that traverses the graph's relationships to construct a comprehensive answer.",
  "learned_prompt_graph_builder": "You are an expert knowledge graph constructor for a GraphRAG system. Your primary goal is to build a narrative-rich graph that captures the causal and sequential flow of events in a story, enabling rich plot-focused queries.\n\nWhen processing the provided text, follow these instructions:\n\n1.  **Identify and Represent Key Entities:**\n    *   Extract significant entities (e.g., characters, major objects, locations, organizations) that play a role in the narrative.\n    *   For each entity, provide a *concise description* focusing on their relevance to the plot. Avoid exhaustive property extraction unless it directly impacts narrative causality or progression.\n\n2.  **Prioritize Plot-Driving Relationships:**\n    *   Focus on extracting relationships that explain *how* and *why* events unfold.\n    *   **Crucially, identify and label relationships such as:**\n        *   `causes`: Indicates a direct causal link between events or actions.\n        *   `leads to`: Shows a consequence or result.\n        *   `initiates event`: Marks the start of a significant occurrence.\n        *   `conflicts with`: Describes opposition or struggle between entities or events.\n        *   `sequences of`: Denotes events occurring in a specific order.\n        *   `precedes`: Explicitly states one event happens before another.\n        *   `consequence of`: Explicitly states one event is the result of another.\n        *   `involved in`: Links entities to events.\n    *   For each relationship, provide *brief, specific evidence* from the text that supports the connection.\n\n3.  **Represent Events as First-Class Nodes:**\n    *   Treat significant narrative events as distinct `Event` nodes.\n    *   Link `Event` nodes to the `Entity` nodes involved in them.\n    *   Connect `Event` nodes to each other using plot-driving temporal and causal relationships (e.g., `precedes`, `consequence of`, `causes`).\n\n4.  **Structure for Narrative Flow:**\n    *   Construct the graph with a narrative-centric approach. The sequence and causality of events should be the primary organizing principle, with entities described in relation to these events.\n    *   Avoid an entity-centric bias; the plot's progression is paramount.\n\n5.  **Output Format:**\n    *   Output the graph in JSON format, with distinct lists for `entities`, `events`, and `relationships`.\n    *   Ensure each node and relationship has a unique `id`.\n    *   Relationships should clearly reference the `source` and `target` node IDs and have a descriptive `label` (from the prioritized list above) and concise `evidence`.\n\nBy focusing on events and their causal/sequential connections, you will create a graph that accurately represents the narrative's progression, making it ideal for plot-driven analysis.",
  "hyperparameters_graph_agent_critique": "The chosen chunk size of 300 appears to be a reasonable starting point but has contributed to some of the observed graph limitations, particularly in relation to narrative coherence and central plot elements.\n\n**Critique on Chunk Size (300):**\n\n1.  **Insufficient Context for Narrative Flow (Plot Nodes):** A chunk size of 300, while not excessively small, might still be too granular to capture comprehensive narrative arcs or plot progression within a single chunk. The critique highlights a lack of \"Central Narrative Nodes\" and the difficulty in finding \"plot\" or \"story\" nodes. This suggests that critical plot-driving events or thematic connections are being split across chunk boundaries. When a chunk is too small, an LLM generating a graph from it might only extract localized information, missing the broader context needed to identify overarching plot structures or synthesize relationships that span multiple chunks.\n\n2.  **Over-reliance on Generic Relationships and Entity Fragmentation:** The large number of generic relationship types like \"involved in\" and the imbalance in entity types (303 \"\"s vs. fewer \"Event\" or \"Person\" nodes) can be exacerbated by a chunk size that doesn't consistently capture meaningful interactions. If a 300-token chunk contains multiple vague mentions of an entity but not the specific actions or events they are involved in, the resulting graph might over-represent these generic entities and relationships. Conversely, if a critical plot event involves several entities and is split across two chunks, the relationships between those entities might be fragmented or weakened when the graphs are merged, leading to a less connected graph.\n\n3.  **Limited Causal Linkages Across Chunks:** While the critique recommends introducing more semantically rich relationships like `precedes_event` and `causes_outcome`, a fixed chunk size might hinder the LLM's ability to infer these across boundaries. If a cause-and-effect relationship spans two chunks, the LLM processing each chunk independently might not have enough information to establish a strong causal link during graph generation. This contributes to the graph's sparsity and the difficulty in tracing narrative consequences.\n\n**Recommendations for Chunk Size Improvement:**\n\n*   **Experiment with Larger Chunk Sizes:** Consider increasing the chunk size (e.g., to 500-750 tokens) to allow LLMs to process more contextual information within each chunk. This could improve the likelihood of capturing more complete events, character interactions, and thematic elements, potentially leading to more specific and narrative-rich nodes and relationships.\n*   **Adaptive Chunking or Overlapping Chunks:** Instead of a fixed size, explore adaptive chunking strategies that try to end chunks at natural narrative breaks (e.g., sentence boundaries, paragraph ends). Alternatively, using overlapping chunks can ensure that information at the boundaries of chunks is processed in multiple contexts, potentially strengthening cross-chunk relationships.\n*   **Prioritize Chunk Content:** Ensure that the chunking strategy prioritizes retaining key narrative elements (events, character introductions, conflicts) within individual chunks as much as possible, even if it means slightly varying chunk sizes.",
  "graph_builder_agent_critique": "This prompt for graph construction in GraphRAG exhibits several weaknesses that hinder the creation of a narrative-rich graph suitable for plot-focused queries.\n\n**1. Overemphasis on Granular Entity Properties vs. Narrative Relationships:**\nThe prompt instructs the LLM to extract detailed `properties` for each entity (e.g., \"age, role, description\"). While useful for general knowledge graphs, this level of detail often distracts from identifying the core narrative actions and causal links that drive a plot. The sheer volume of property extraction can dilute the focus on crucial relationships.\n\n**2. Lack of Explicit Instruction for Plot-Relevant Relationships:**\nThe prompt is too generic in its request for \"all the relationships.\" It doesn't guide the LLM to prioritize or identify relationships that are essential for understanding narrative progression. Relationships like `causes`, `leads to`, `initiates event`, `conflict with`, or `sequence of` are not prompted for, leading to a graph that is descriptive rather than dynamic.\n\n**3. Undervaluing Event Representation:**\nThe prompt doesn't specifically guide the LLM to represent events as distinct, connectable nodes. While entities are requested, events, which are the building blocks of a plot, are not emphasized as first-class citizens that can be linked to characters and other events via plot-driving relationships (e.g., `precedes`, `consequence of`).\n\n**4. Entity-Centric Bias:**\nThe prompt's structure naturally leads to an entity-centric graph. The focus is on identifying entities and then finding relationships *among* them. This contrasts with a narrative-centric approach where the *actions* and *sequences of events* involving entities are the primary focus, dictating the structure of the graph.\n\n**5. Ambiguity in Relationship Definition:**\nWhile the prompt asks for a `description` of why entities are related and `evidence`, the breadth of this request, combined with the lack of specific plot-oriented relationship types, results in the fragmentation observed in the generated graph (many relationship types with few instances). This suggests the LLM is inferring many tangential connections rather than focusing on the core narrative.\n\nIn summary, the prompt needs to be reframed to prioritize the extraction of causal and sequential relationships that define a plot, rather than focusing excessively on granular entity properties and a broad, unprioritized set of general relationships. The LLM should be instructed to identify and represent events and their connections more prominently.",
  "retrieval_planner_agent_critique": "This retrieval plan is repetitive and ineffective for answering \"What is the plot of the story?\".\n\n**Critique:**\n\n1.  **Repetitive and Unproductive Strategy:** All proposed moves (1-5) suggest using `search_nodes_by_keyword` with terms like \"plot\" or \"story.\" This is a fundamentally flawed strategy for two reasons:\n    *   **Abstract Concepts vs. Concrete Elements:** The \"plot\" is an emergent property of the story, not typically a node explicitly labeled \"plot\" in a knowledge graph. A graph derived from text will contain nodes representing characters, events, locations, objects, and their relationships, which collectively form the plot. Searching for abstract terms like \"plot\" or \"story\" is unlikely to yield meaningful starting points in the graph.\n    *   **Lack of Graph Exploration:** The plan shows no progression. It repeatedly attempts the same type of search without considering the graph's structure or available exploration tools beyond the initial search. It doesn't leverage the rich information about node and relationship types provided in the graph description.\n\n2.  **Missed Opportunities with Graph Description:** The plan ignores crucial information provided about the graph:\n    *   **Entity Types:** The graph contains \"Event\" (36), \"Location\" (29), and \"Person\" (10) nodes. These are the building blocks of a narrative and are much more likely to contain plot-relevant information than a generic \"plot\" node.\n    *   **Relationship Types:** Key relationships like \"involved in,\" \"initiates event,\" \"causes,\" \"conflicts with,\" \"traveled to,\" etc., directly describe actions and causality, which are central to a plot.\n\n3.  **No Adaptability to Empty Results:** The plan does not account for the possibility that \"plot\" or \"story\" might not be present as keywords. If these searches yield no results (as has been the case in previous iterations), the agent should pivot to a different strategy.\n\n**Recommendations for Improvement:**\n\n1.  **Prioritize Narrative Elements:** Instead of abstract keywords, the initial search should focus on concrete narrative components.\n    *   **Start with \"Event\" nodes:** Use `search_nodes_by_types(node_type='Event')` as a starting point, as events are the core of any plot.\n    *   **Broad Noun/Verb Search:** If keyword search is necessary, consider broader terms that capture common elements of stories (e.g., character names if known, or generic nouns/verbs indicating actions).\n\n2.  **Leverage Relationship Types:** Once initial nodes are found, use `search_relations_by_type` for relationships like \"initiates event,\" \"causes,\" \"conflicts with,\" or \"involved in\" to understand the causal chain and interactions that constitute the plot.\n\n3.  **Iterative Exploration:** Employ `get_neighbors` to expand from initial nodes, progressively building a narrative context. If a search yields no results, the agent should explicitly try a different function or node type.\n\nIn essence, the agent needs to transition from a keyword-matching approach to a structural exploration of the graph, focusing on narrative components and their relationships.",
  "answer_generation_critique": "The current prompt is **functionally inadequate** for handling situations where the retrieved information (in this case, an \"empty graph\") does not directly contain the answer to the user's question. While it has some good intentions regarding synthesis and handling insufficient information, it fails to address the core problems highlighted in the feedback.\n\nHere's a breakdown of the critique and specific suggestions for prompt improvement:\n\n**Critique of Current Prompt:**\n\n1.  **Fails to address the \"Why\":** The prompt's guidance in point 3 (\"Handle Insufficient Information Proactively\") is too generic. It tells the system *what* to state (limitations, missing elements), but not *how* to explain the *specific* reason for failure in a user-friendly way. The current prompt doesn't guide the LLM to explain *why* the graph is empty or what that means in the context of the query.\n    *   **Issue:** The system responded with a technical explanation (\"empty graph with no nodes\") without bridging the gap to the user's need for a plot.\n    *   **Prompt Deficiency:** Lacks instructions to explain technical terms or relate them to the user's query.\n\n2.  **Insufficient Guidance on Next Steps/User Guidance:** Point 3 suggests offering \"related details that *are* present.\" However, in the case of an empty graph, there *are no* related details. The prompt doesn't explicitly tell the LLM to prompt the user for more information or clarify what kind of input is expected.\n    *   **Issue:** The response provided no direction for the user.\n    *   **Prompt Deficiency:** Needs explicit instructions to ask clarifying questions or request specific types of input when core information is missing.\n\n3.  **Lack of User-Centricity and Empathy:** The prompt's tone is professional but doesn't encourage empathy or a more conversational, helpful style, especially when failing. The feedback explicitly states the response was \"unhelpful and lacks user-centricity.\"\n    *   **Issue:** The response was dry and abrupt.\n    *   **Prompt Deficiency:** The prompt doesn't specify a tone or provide phrasing examples for apologetic or guiding statements.\n\n4.  **Ambiguity in \"Synthesize and Infer\":** While good in principle, \"Attempt to synthesize the available fragments\" and \"Construct a partial answer\" are difficult to apply to a truly empty graph. The prompt doesn't provide a fallback strategy for when there are *zero* fragments to synthesize.\n    *   **Issue:** The prompt assumes there will be *some* fragments, even if few.\n    *   **Prompt Deficiency:** Needs a directive for situations where there is absolutely *no* data to work with, beyond stating it's insufficient.\n\n**Suggested Prompt Improvements:**\n\nTo address these issues, the prompt needs to be more directive and empathetic, especially concerning failure scenarios.\n\n**Revised Prompt Guidance (Focusing on key areas):**\n\n*   **Add a preamble for failure scenarios:**\n    > \"If the `Information` is fundamentally insufficient or indicates a lack of data (e.g., an empty graph, no relevant documents found), **first, express inability to answer directly and empathetically.** Then, **clearly explain *why* the information is insufficient in user-understandable terms**, avoiding technical jargon where possible or explaining it if necessary (e.g., 'I couldn't find any story details because the data I accessed was empty'). **Crucially, guide the user on what information is needed to fulfill their request.** Offer specific examples of what they can provide (e.g., 'Could you please provide the story's text, or its title and author?'). If applicable, suggest alternative actions the user might take (e.g., 'Would you like me to try generating a story based on a theme?').\"\n\n*   **Refine \"Synthesize and Infer\" for zero data:**\n    > \"If the `Information` is fragmented, attempt to synthesize it. **However, if the `Information` contains absolutely no relevant data (e.g., an empty graph), do not attempt synthesis. Instead, clearly state the lack of data and proceed to guide the user as described above.** Do not invent information or speculate.\"\n\n*   **Emphasize User Guidance:**\n    > \"When information is insufficient, your primary goal is to assist the user in obtaining a useful response. This includes **proactively asking for clarification or more data**. Frame your inability to answer as an opportunity to help the user refine their query or provide necessary context.\"\n\nBy incorporating these specific directives, the prompt will better equip the LLM to generate helpful, user-centric responses even when faced with system-level failures like an empty graph, transforming a dead-end interaction into a constructive one.",
  "graph_builder_prompt": "\nYou will be given a text. Your goal is to identify entities in the text and all the relationships among the identified entities.\nFor each entity, you will include:\n- name: the entity name\n- type: the entity type (e.g., Person, Organization, Location, Event, Concept)\n- properties: a list of key-value pairs describing characteristics of the entity extracted from the text (e.g., for a person: age, role, description; for a location: description, significance). Each property should have a \"key\" and \"value\" field.\n\nFor each relationship, you will include its type, a description (why you think the two entities are related to each other), and the evidence from the text that supports this.\nThe relationships must be among the extracted entities.\nProvide a list of triplets in your answer.\n\nText:\n{TEXT_CHUNK}\n\nProvide the reasoning that led to your response.\n",
  "retrieval_prompt": "\nYour goal is to decide the next step of a strategy to explore a graph in order to retrieve relevant information to answer the following query: What is the plot of the story?.\n\nA high-level description of the graph is the following: This graph contains 417 nodes and 549 relationships. The graph density is 0.0063, indicating a sparsely connected network. The graph is fully connected with a fragmentation index of 0.0000. The entities consist of 303 \"\"s, 36 \"Event\"s, 29 \"Location\"s, 22 \"Object\"s, 10 \"Person\"s, 6 \"Concept\"s, 5 \"Weapon\"s, 2 \"Creature\"s, 2 \"Organization\"s, 1 \"PersonGroup\", and 1 \"Plant\". The relationships include 51 \"involved in\" relationships, 12 \"initiates event\" relationships, 11 \"attacks\" relationships, 11 \"contains\" relationships, 9 \"causes\" relationships, 8 \"associated with\" relationships, 8 \"captures\" relationships, 8 \"traveled to\" relationships, 8 \"wears\" relationships, 7 \"conflicts with\" relationships, 7 \"uses\" relationships, 5 \"inhabitant of\" relationships, 5 \"leads to\" relationships, 5 \"travels towards\" relationships, 4 \"asks about\" relationships, 4 \"causes death of\" relationships, 4 \"interacted with\" relationships, 4 \"is\" relationships, 4 \"learned tongue of\" relationships, 4 \"located in\" relationships, 4 \"located on\" relationships, 4 \"observed\" relationships, 4 \"originates from\" relationships, 4 \"wants to save\" relationships, 3 \"approaches\" relationships, 3 \"believes world is like\" relationships, 3 \"calls\" relationships, 3 \"causes fear in\" relationships, 3 \"consequence of\" relationships, 3 \"entered\" relationships, 3 \"forbidden to\" relationships, 3 \"from\" relationships, 3 \"guards\" relationships, 3 \"intends to rescue\" relationships, 3 \"named by\" relationships, 3 \"observes\" relationships, 3 \"produced\" relationships, 3 \"produced by\" relationships, 3 \"restoring\" relationships, 3 \"sees\" relationships, 3 \"targets\" relationships, 3 \"trapped on\" relationships, 3 \"traveled from\" relationships, 2 \"attacked\" relationships, 2 \"attacked by\" relationships, 2 \"brother of\" relationships, 2 \"called\" relationships, 2 \"carried noork to\" relationships, 2 \"carries\" relationships, 2 \"catches\" relationships, 2 \"chooses for sacrifice to\" relationships, 2 \"claims to be\" relationships, 2 \"commands\" relationships, 2 \"confronts\" relationships, 2 \"contrasted with\" relationships, 2 \"daughter of\" relationships, 2 \"dons\" relationships, 2 \"dwell in\" relationships, 2 \"enters\" relationships, 2 \"exile from\" relationships, 2 \"gives robe to\" relationships, 2 \"guarded by\" relationships, 2 \"guards entrance to\" relationships, 2 \"held in\" relationships, 2 \"identified by\" relationships, 2 \"intends to take\" relationships, 2 \"intends to take to\" relationships, 2 \"is a\" relationships, 2 \"killed\" relationships, 2 \"leader of\" relationships, 2 \"leaned against\" relationships, 2 \"located near\" relationships, 2 \"mate\" relationships, 2 \"obtained\" relationships, 2 \"opposed enslavement of\" relationships, 2 \"perceived as\" relationships, 2 \"precedes\" relationships, 2 \"prepares to battle\" relationships, 2 \"promises robe to\" relationships, 2 \"provides information about\" relationships, 2 \"searches for\" relationships, 2 \"sheds\" relationships, 2 \"sister of\" relationships, 2 \"strips of possessions\" relationships, 2 \"swung close to\" relationships, 2 \"trailed\" relationships, 2 \"traps\" relationships, 2 \"traveled into\" relationships, 2 \"wants to rescue\" relationships, 2 \"warned about\" relationships, 2 \"wields\" relationships, 2 \"worships\" relationships, 1 \"accuses\" relationship, 1 \"addresses\" relationship, 1 \"advocated against enslaving\" relationship, 1 \"agrees to help\" relationship, 1 \"antagonist\" relationship, 1 \"approached\" relationship, 1 \"arrived in\" relationship, 1 \"asked about\" relationship, 1 \"attempts to communicate with\" relationship, 1 \"attempts to rescue\" relationship, 1 \"attracted to\" relationship, 1 \"avoided valley of\" relationship, 1 \"believes are not immortal demons\" relationship, 1 \"calls traitor\" relationship, 1 \"came from\" relationship, 1 \"captor destination\" relationship, 1 \"captured\" relationship, 1 \"captured by\" relationship, 1 \"carried by\" relationship, 1 \"causes incapacitation of\" relationship, 1 \"causes injury to\" relationship, 1 \"causes to breathe deeply\" relationship, 1 \"challenges\" relationship, 1 \"chief is\" relationship, 1 \"chosen for sacrifice to\" relationship, 1 \"citizen of\" relationship, 1 \"claims can be skinned\" relationship, 1 \"claims can be trapped\" relationship, 1 \"climbed over\" relationship, 1 \"combatant in\" relationship, 1 \"commented on hair color of\" relationship, 1 \"communicates intention to\" relationship, 1 \"concentrated on\" relationship, 1 \"concerns\" relationship, 1 \"concerns sacrifice to\" relationship, 1 \"covet\" relationship, 1 \"crosses field towards\" relationship, 1 \"damages\" relationship, 1 \"darted toward\" relationship, 1 \"descends to\" relationship, 1 \"devours\" relationship, 1 \"donned\" relationship, 1 \"dwells among\" relationship, 1 \"dwelt among\" relationship, 1 \"emits\" relationship, 1 \"enemies\" relationship, 1 \"enemy of\" relationship, 1 \"escaped death of\" relationship, 1 \"escaped from\" relationship, 1 \"establishes\" relationship, 1 \"etext source for\" relationship, 1 \"evades\" relationship, 1 \"exclaimed against\" relationship, 1 \"exclaimed at\" relationship, 1 \"explains to\" relationship, 1 \"father of\" relationship, 1 \"father's woman\" relationship, 1 \"fears\" relationship, 1 \"fears capture of\" relationship, 1 \"filled\" relationship, 1 \"flees from\" relationship, 1 \"friend\" relationship, 1 \"friend of\" relationship, 1 \"gave\" relationship, 1 \"gave name to\" relationship, 1 \"greeted\" relationship, 1 \"greets\" relationship, 1 \"guards entrance to pits of\" relationship, 1 \"has\" relationship, 1 \"headed towards\" relationship, 1 \"heading towards\" relationship, 1 \"hears\" relationship, 1 \"hears about\" relationship, 1 \"hears voice of\" relationship, 1 \"held prisoner in\" relationship, 1 \"hid bodies in\" relationship, 1 \"hides bodies in\" relationship, 1 \"hides bodies in chamber of\" relationship, 1 \"hides bodies of\" relationship, 1 \"holds hands with\" relationship, 1 \"home was\" relationship, 1 \"hung on\" relationship, 1 \"identified\" relationship, 1 \"identified self to\" relationship, 1 \"ignored by\" relationship, 1 \"illuminated by\" relationship, 1 \"implied associated with\" relationship, 1 \"impressed by\" relationship, 1 \"informed\" relationship, 1 \"inhabits\" relationship, 1 \"injures\" relationship, 1 \"inserted into\" relationship, 1 \"instilled fear in\" relationship, 1 \"instructed to\" relationship, 1 \"instructs\" relationship, 1 \"intended destination\" relationship, 1 \"intends to save\" relationship, 1 \"intends to take to brother's village\" relationship, 1 \"intends to take to city\" relationship, 1 \"intends to visit\" relationship, 1 \"interacts with\" relationship, 1 \"is beneath\" relationship, 1 \"is caught by\" relationship, 1 \"is from\" relationship, 1 \"is held in\" relationship, 1 \"is located near\" relationship, 1 \"is near\" relationship, 1 \"is now\" relationship, 1 \"is one of\" relationship, 1 \"is separated by\" relationship, 1 \"is smaller than\" relationship, 1 \"is trailing\" relationship, 1 \"journeyed through valley of\" relationship, 1 \"landed in\" relationship, 1 \"located beyond\" relationship, 1 \"location of\" relationship, 1 \"may return to\" relationship, 1 \"moves along\" relationship, 1 \"not present on\" relationship, 1 \"observed by\" relationship, 1 \"occurs in\" relationship, 1 \"occurs in context of\" relationship, 1 \"occurs in territory of\" relationship, 1 \"occurs near\" relationship, 1 \"occurs on\" relationship, 1 \"offers rescue to\" relationship, 1 \"offers to take along\" relationship, 1 \"one day's march from\" relationship, 1 \"opens into\" relationship, 1 \"paddles\" relationship, 1 \"people from\" relationship, 1 \"perceives scent of\" relationship, 1 \"perched on\" relationship, 1 \"possesses\" relationship, 1 \"prefers gravity of\" relationship, 1 \"prepared to battle\" relationship, 1 \"protects\" relationship, 1 \"provided information to\" relationship, 1 \"puts on\" relationship, 1 \"reaches for\" relationship, 1 \"rebuilding\" relationship, 1 \"recognized\" relationship, 1 \"recognizes\" relationship, 1 \"referred to as by\" relationship, 1 \"related to\" relationship, 1 \"remembers\" relationship, 1 \"removes clothing from\" relationship, 1 \"replied\" relationship, 1 \"replies to\" relationship, 1 \"restoring structure of\" relationship, 1 \"retrieves\" relationship, 1 \"returned toward\" relationship, 1 \"returned towards\" relationship, 1 \"rulers call traitor\" relationship, 1 \"said\" relationship, 1 \"searched for\" relationship, 1 \"secured by\" relationship, 1 \"seeks information about\" relationship, 1 \"seeks secret of\" relationship, 1 \"sees stationed at\" relationship, 1 \"serves\" relationship, 1 \"sibling of\" relationship, 1 \"skinned\" relationship, 1 \"slipped in\" relationship, 1 \"snatches\" relationship, 1 \"squatted in\" relationship, 1 \"stolen skin of\" relationship, 1 \"swung to side of\" relationship, 1 \"takes\" relationship, 1 \"takes hand of\" relationship, 1 \"takes place in\" relationship, 1 \"tasted odor of\" relationship, 1 \"tears from sockets\" relationship, 1 \"told\" relationship, 1 \"touches\" relationship, 1 \"tracking\" relationship, 1 \"tracks\" relationship, 1 \"trails\" relationship, 1 \"transported noork to\" relationship, 1 \"trapped\" relationship, 1 \"trapped by\" relationship, 1 \"traveled spaceward in\" relationship, 1 \"travels between\" relationship, 1 \"travels to\" relationship, 1 \"traversed\" relationship, 1 \"vanished from\" relationship, 1 \"walked toward\" relationship, 1 \"wants to conquer\" relationship, 1 \"wants to escape from\" relationship, 1 \"wants to go with\" relationship, 1 \"wants to make invincible\" relationship, 1 \"wants to mate with\" relationship, 1 \"warns of\" relationship, 1 \"watched\" relationship, 1 \"wear\" relationship, 1 \"wears robes of\" relationship, 1 \"wedged into\" relationship, 1 \"worked in\" relationship, and 1 \"worn by\" relationship. The most common entity type is \"\" with 303 instances. The most frequent relationship type is \"involved in\" with 51 occurrences.\n\nYou must choose one of the following functions:\n\n- search_nodes_by_keyword(keyword): search for all the nodes whose labels contain the given keyword\n- search_nodes_by_types(node_type): search for all the nodes whose type property contains the given type\n- get_neighbors(node_name): get all neighbors of a node with the given name\n- search_relations_by_type(relation_type): search for all the triplets whose relationship matches the type\n- identify_communities(node_name): find the community (connected component) containing a specific node\n- analyze_path(start_node_name, end_node_name): find the shortest path between two nodes\n- find_hub_nodes: find the top 3 hub nodes with the highest connectivity\n\nThe subgraphs you retrieved so far are the following:\n\n{RETRIEVED_CONTEXT}\n\nChoose one of the functions and specify the arguments.\n\nProvide the reasoning that led to your response.\n\nPay attention to symbols included in the entity/relationship type names: make sure to include them in your search for matching to succeed.\nAlso, pay attention to symbols included in the functions names. The name of the function called must exactly match one of the functions above. \n"
}